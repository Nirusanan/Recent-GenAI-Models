{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Base Model: meta-llama/Llama-3.1-8B"
      ],
      "metadata": {
        "id": "qf6Lb-5KG0Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"transformers==4.47.1\"  \"accelerate==1.3.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEecMJg1k2Y5",
        "outputId": "2ceb7f4b-4f17-4992-cbeb-ec36b3c504f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502,
          "referenced_widgets": [
            "9710dab1777b42848ac4fec6417d9921",
            "5da8ea9bcb374b0d910c6c3a8a0f99b8",
            "f90a6cf498964a6b849701626e8e5ef4",
            "25bd7ac74cae405d87217c8894c54094",
            "7c7f84f8dd2a4819b248489ee4078812",
            "e45e071e963847c6a0093ae0880d33c1",
            "bd7aa19254114039ab0f53a59c56e92d",
            "e71784e2e98b46ec8f1b2b11d9a73e13",
            "7257b01370724fca9c4776a25b9bac74",
            "d8499ebef422444fb06e417fb154ebb0",
            "a736f28a542146629e95550d79960ae6",
            "3b75169194cd46fd80f5b7bf46780ad0",
            "e59e186e6c244f3bb4dd01e0c6538ded",
            "3fdd8f6020ff463487aa8f9a56914277",
            "fc868aa011ab430eba2528bdc5a7f406",
            "144105c5e0974a77b34d282e0401c065",
            "cbb2e7cca2274e1798282e4d59a6023a",
            "9ab15f03bca54e1c92ec89519f98570d",
            "1c3c9ad3454d4c2c97b9459e1d4c75bf",
            "7d0456698a3741288b1bb0682adeead1",
            "468773a65788405893014c6dae75b5e5",
            "2b5f42acc802430a84cdd158512504b6",
            "5e3caca4dec54e319d13c1941e06f466",
            "dd361ad18ae74597ad18c4766a8aaf88",
            "dd1a53994e9a4bf4916bf0955d6184cc",
            "ffaa1de8ad164556bf09ffdcbb030c7f",
            "ccb342bc966e4a24950589db2015c6c6",
            "cb26f87d9806434ab7840a4efcd65ae4",
            "0a40aabbcd9a4583b1b0d08bb1b7265d",
            "2d79998aea1f406a85919b24510a1614",
            "2616851a61dc46068954356e086128f5",
            "43dab3838c2c43ba941f3525d1e8b972",
            "96b6daa0d7ff44948acfa554bee0e4cc",
            "3eb80169566444b0b7413114046706ae",
            "3d9e8124fdf6499a89a7bc84b3a6b209",
            "394446899a55444f9a10b2397b04a6a8",
            "099dd0795bef41a580b65beed9317167",
            "2f3c97b81aeb4ce3a4ad4811981d62a5",
            "c6b7b06579bd443daa34740ffb6d3e82",
            "7616dfd03aaf480297a77391d9dadf83",
            "998cec31ffce4ab4b8cf7d0b7a4eb103",
            "5b2ee1d0d14e45f98e221c39eed58d0a",
            "71c5226ee07f4d258ad6749f840740b0",
            "5134a1a558334898a63902212aed49c9",
            "6a5f1940dc3345cdaa7e4ed18b98f9de",
            "978da0112b7744039645d82e2b1df5ec",
            "adbde1b2a15f4fbf8cd02722e203fa6d",
            "62fbec453176415da22970a3dc129b84",
            "a1a7cc00c0cc49d4b0ea8ccf27391417",
            "b8a95236750a4e78825a69de758108c2",
            "045b2c68992a455c8b2ddbb3d261fdde",
            "9e55d151ad554becb6c4e970519313c1",
            "8ac10f87d8e040c88c01174c564d4954",
            "89bf71d3f0334e029d45616683bdb05b",
            "3601b64bc2274027988882f76255dae8",
            "1b34142786bf4f8fb863b7fd556c574a",
            "39cc28fe55ab4b9b8d2856a81aad4505",
            "cafb2e87ec304891829ad5dca61af64d",
            "480fe66d5b1342e98ea6384a1de95940",
            "ee9a9b7c8ac3472b9c36c984e2999c61",
            "47072b718c724672ba9fa6225ff36171",
            "1d7b092feca54d15903678148a0c512a",
            "e50a028e8caa4620908a97111a720be2",
            "7f5a1a145aa54dd7b14b125390f5c18c",
            "764926abc8934bc893fd4d979351e5b9",
            "3ba5246b047a4c2aad750d0677f208e8",
            "3d43224354d64a7db2f5a0b7f34245d1",
            "b29d8f063985466d805bc166e259f3c5",
            "4935d6abdc0c442f934a6e885ac70669",
            "d4cacbeabdff46b19f7aa3be8cb28814",
            "fcc11995b8d44a169bbe30fb41e32a01",
            "9f2a6136e30341599f6f6eea9d7a9cad",
            "33f808b0b1194434bfc306f8dae6c883",
            "7fd862af70674b86b611da23c0e9e380",
            "8bcb907bd3b647a18c5ac6e2a398610b",
            "561b3cc024ea41b9b976d6b6ce856728",
            "e2f74e872ed747fbb2cf516efcac86ad",
            "ea420909f81541bb963a1ed450b0c688",
            "2338b6fb21c841168d42fd95e5617ed9",
            "9fed0c9ad77a461dbcb3cc8fd9125acc",
            "3fc43bc6185245008ae0a813eeeb51e3",
            "53a76fded5064d0096a64c89e83a3995",
            "e4c5b4d9d9064963adfac76763bd0294",
            "65908a95c5634d148a5df309bb8f12ca",
            "0bb1c48674464971b4cf214bd299362a",
            "46cd6492eaac4b8fab5d85c29d0f5660",
            "80a2c7c765e64b31b7462d4ca0181502",
            "befb558ee1544c57b41d6c1d7ca3ad0c",
            "55749f1012dd49d7ae86c887e0d6ce5f",
            "e4c8e2949cb647e0ae5dc54efcb9fc98",
            "345d280411d64c70bc2ed73fb5164d6f",
            "e75c91d2bac94b8c97e7861331cf829c",
            "24b1db28700e45dbb0bdbd498a916b92",
            "874b34a74bf848938ef819d29a6d5acf",
            "743feb22718e4cc6b8be28e1d0ec04ec",
            "ba9d3cec53974e8097fe7bdf77b5e8f7",
            "386aa8e8ac424cb2b8efa6c49a363995",
            "d05ff4cfefa8425fbd389cb0fb719590",
            "e7b58b1825b240f1b3d4b8125297bb69"
          ]
        },
        "id": "z8x6q8-_kjF6",
        "outputId": "e75a859f-1703-48f7-9814-74ecf9a53cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9710dab1777b42848ac4fec6417d9921"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b75169194cd46fd80f5b7bf46780ad0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e3caca4dec54e319d13c1941e06f466"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-000002.safetensors:   0%|          | 0.00/8.67G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3eb80169566444b0b7413114046706ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-000002.safetensors:   0%|          | 0.00/7.39G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a5f1940dc3345cdaa7e4ed18b98f9de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b34142786bf4f8fb863b7fd556c574a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d43224354d64a7db2f5a0b7f34245d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.06k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea420909f81541bb963a1ed450b0c688"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55749f1012dd49d7ae86c887e0d6ce5f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"find differention of f(x) = 2x^2+sin(x)/3x^2\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=2048\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHw8DDN4kreq",
        "outputId": "030d9291-a1d1-40cf-9f27-0c3cff882b40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "I need to find the derivative of the function \\( f(x) = \\frac{2x^2 + \\sin(x)}{3x^2} \\).\n",
            "\n",
            "First, I'll simplify the function by separating the terms in the numerator.\n",
            "\n",
            "Next, I'll apply the quotient rule to differentiate the function, which involves taking the derivative of the numerator and the denominator separately.\n",
            "\n",
            "After calculating the derivatives, I'll simplify the expression to obtain the final derivative.\n",
            "</think>\n",
            "\n",
            "To find the differentiation of the function \\( f(x) = \\frac{2x^2 + \\sin(x)}{3x^2} \\), follow these steps:\n",
            "\n",
            "### Step 1: Simplify the Function\n",
            "First, rewrite the function to separate the terms:\n",
            "\n",
            "\\[\n",
            "f(x) = \\frac{2x^2}{3x^2} + \\frac{\\sin(x)}{3x^2}\n",
            "\\]\n",
            "\n",
            "Simplify each term:\n",
            "\n",
            "\\[\n",
            "f(x) = \\frac{2}{3} + \\frac{\\sin(x)}{3x^2}\n",
            "\\]\n",
            "\n",
            "### Step 2: Differentiate Term by Term\n",
            "Differentiate each term separately.\n",
            "\n",
            "1. **First Term: \\( \\frac{2}{3} \\)**\n",
            "   \\[\n",
            "   \\frac{d}{dx}\\left(\\frac{2}{3}\\right) = 0\n",
            "   \\]\n",
            "\n",
            "2. **Second Term: \\( \\frac{\\sin(x)}{3x^2} \\)**\n",
            "   Use the quotient rule:\n",
            "   \\[\n",
            "   \\frac{d}{dx}\\left(\\frac{u}{v}\\right) = \\frac{u'v - uv'}{v^2}\n",
            "   \\]\n",
            "   Let \\( u = \\sin(x) \\) and \\( v = 3x^2 \\).\n",
            "\n",
            "   - Find \\( u' \\):\n",
            "     \\[\n",
            "     u' = \\cos(x)\n",
            "     \\]\n",
            "   \n",
            "   - Find \\( v' \\):\n",
            "     \\[\n",
            "     v' = 6x\n",
            "     \\]\n",
            "   \n",
            "   Apply the quotient rule:\n",
            "   \\[\n",
            "   \\frac{d}{dx}\\left(\\frac{\\sin(x)}{3x^2}\\right) = \\frac{\\cos(x) \\cdot 3x^2 - \\sin(x) \\cdot 6x}{(3x^2)^2}\n",
            "   \\]\n",
            "   Simplify the numerator:\n",
            "   \\[\n",
            "   = \\frac{3x^2\\cos(x) - 6x\\sin(x)}{9x^4}\n",
            "   \\]\n",
            "   Simplify the fraction:\n",
            "   \\[\n",
            "   = \\frac{x\\cos(x) - 2\\sin(x)}{3x^3}\n",
            "   \\]\n",
            "\n",
            "### Step 3: Combine the Derivatives\n",
            "Combine the derivatives of both terms:\n",
            "\n",
            "\\[\n",
            "f'(x) = 0 + \\frac{x\\cos(x) - 2\\sin(x)}{3x^3} = \\frac{x\\cos(x) - 2\\sin(x)}{3x^3}\n",
            "\\]\n",
            "\n",
            "### Final Answer\n",
            "\\[\n",
            "\\boxed{\\frac{x\\cos(x) - 2\\sin(x)}{3x^3}}\n",
            "\\]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"There are two numbers 9.99 and 9.12, what is the biggest number\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=500\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "Ot8p7TAZkriK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6882a2-a086-4a71-daec-822089718430"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "First, I need to identify the two numbers provided: 9.99 and 9.12.\n",
            "\n",
            "To compare these numbers accurately, I'll align their decimal places by writing them with the same number of decimal places.\n",
            "\n",
            "Once they are aligned, I can compare each digit starting from the left. Both numbers have the same whole number part, which is 9.\n",
            "\n",
            "Next, I'll compare the tenths place: 9 in 9.99 is greater than 1 in 9.12.\n",
            "\n",
            "Since the tenths place of 9.99 is larger, I can conclude that 9.99 is the bigger number.\n",
            "</think>\n",
            "\n",
            "**Solution:**\n",
            "\n",
            "To determine which number is larger between **9.99** and **9.12**, follow these steps:\n",
            "\n",
            "1. **Align the Decimal Places:**\n",
            "\n",
            "   It's helpful to write both numbers with the same number of decimal places for an accurate comparison.\n",
            "\n",
            "   \\[\n",
            "   \\begin{align*}\n",
            "   9.99 \\\\\n",
            "   9.12 \\\\\n",
            "   \\end{align*}\n",
            "   \\]\n",
            "\n",
            "2. **Compare the Numbers Digit by Digit:**\n",
            "\n",
            "   - **Whole Number Part:**\n",
            "     - Both numbers have the same whole number part: **9**.\n",
            "\n",
            "   - **Tenths Place:**\n",
            "     - Compare the tenths place:\n",
            "       - **9** (from 9.99) vs. **1** (from 9.12)\n",
            "     - **9** is greater than **1**.\n",
            "\n",
            "3. **Conclusion:**\n",
            "\n",
            "   Since the tenths place of **9.99** is greater than that of **9.12**, we can determine that:\n",
            "\n",
            "   \\[\n",
            "   \\boxed{9.99 \\text{ is the bigger number}}\n",
            "   \\]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<think>\n",
        "First, I need to identify the two numbers provided: 9.99 and 9.12.\n",
        "\n",
        "To compare these numbers accurately, I'll align their decimal places by writing them with the same number of decimal places.\n",
        "\n",
        "Once they are aligned, I can compare each digit starting from the left. Both numbers have the same whole number part, which is 9.\n",
        "\n",
        "Next, I'll compare the tenths place: 9 in 9.99 is greater than 1 in 9.12.\n",
        "\n",
        "Since the tenths place of 9.99 is larger, I can conclude that 9.99 is the bigger number.\n",
        "</think>\n",
        "\n",
        "**Solution:**\n",
        "\n",
        "To determine which number is larger between **9.99** and **9.12**, follow these steps:\n",
        "\n",
        "1. **Align the Decimal Places:**\n",
        "\n",
        "   It's helpful to write both numbers with the same number of decimal places for an accurate comparison.\n",
        "\n",
        "   \\[\n",
        "   \\begin{align*}\n",
        "   9.99 \\\\\n",
        "   9.12 \\\\\n",
        "   \\end{align*}\n",
        "   \\]\n",
        "\n",
        "2. **Compare the Numbers Digit by Digit:**\n",
        "\n",
        "   - **Whole Number Part:**\n",
        "     - Both numbers have the same whole number part: **9**.\n",
        "\n",
        "   - **Tenths Place:**\n",
        "     - Compare the tenths place:\n",
        "       - **9** (from 9.99) vs. **1** (from 9.12)\n",
        "     - **9** is greater than **1**.\n",
        "\n",
        "3. **Conclusion:**\n",
        "\n",
        "   Since the tenths place of **9.99** is greater than that of **9.12**, we can determine that:\n",
        "\n",
        "   \\[\n",
        "   \\boxed{9.99 \\text{ is the bigger number}}\n",
        "   \\]"
      ],
      "metadata": {
        "id": "SjG_o8CqPs2H"
      }
    }
  ]
}
