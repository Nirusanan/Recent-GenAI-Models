{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mixture-of-Experts (MoE) VLM"
      ],
      "metadata": {
        "id": "ThMqBI65ZsP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   DeepSeek-VL2-Tiny: 1.0B  \n",
        "*   DeepSeek-VL2-Small: 2.8B\n",
        "*   DeepSeek-VL2: 4.5B"
      ],
      "metadata": {
        "id": "wKDf3r2y_j1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/deepseek-ai/DeepSeek-VL2"
      ],
      "metadata": {
        "id": "fpJi4BwpeR6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DeepSeek-VL2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V98R3AqPAKTo",
        "outputId": "75883e59-e206-4fb8-aca3-b04d6e949ef5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSeek-VL2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " -e: install a Python package in editable mode.\n",
        "\n",
        " (.): Packages are installed from **pyproject.toml** file in current directory."
      ],
      "metadata": {
        "id": "CZex5iCdjgYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edit the pyproject.toml file:\n",
        "* add \"xformers\" in dependencies"
      ],
      "metadata": {
        "id": "OmvkgozDtFEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "id": "9AoO3JDN9t8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_sNawtTCHLS",
        "outputId": "41b1e797-b574-419d-d109-d2ba199ab76b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeepSeek-VL2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "from deepseek_vl2.models import DeepseekVLV2Processor, DeepseekVLV2ForCausalLM\n",
        "from deepseek_vl2.utils.io import load_pil_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DGunnbdCWoB",
        "outputId": "ca1cb7e5-dc18-4998-f529-154a2677b154"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version is above 3.10, patching the collections module.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"deepseek-ai/deepseek-vl2-tiny\"\n",
        "vl_chat_processor: DeepseekVLV2Processor = DeepseekVLV2Processor.from_pretrained(model_path)\n",
        "tokenizer = vl_chat_processor.tokenizer\n",
        "\n",
        "vl_gpt: DeepseekVLV2ForCausalLM = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888,
          "referenced_widgets": [
            "e408150039564f17a259bbfa11b89056",
            "f5058523ceda4f11b9f02ce4be62260d",
            "21b7f58b0beb4b60b159fa2caac9a61f",
            "15d5f10260734e578b73fa9b2172908c",
            "18102a99fdbe48279541e5ccc66d50e8",
            "1d628b1c38bc44459bf5a3bce04ab6dc",
            "0fbacfb46c1e4cc6b9ec46d2b83d26c8",
            "8c0ed438397e49b3a77073145fa241a8",
            "def96fd2bbcd402f80a307853ec2b547",
            "b71036bb87d94783bb73a9baaa4d048a",
            "b576847f87594e28b5160db1d85125b1",
            "d03919aa3a15406ab30f185c312190e7",
            "3b9bf1198b814b268bc4009583ac2248",
            "7682abdc4ade464c8aed260e90f4f01e",
            "57f1d6fc6f6a46b292845ce393745fcf",
            "7271018a350c4ee3829180f2399bde4c",
            "761d692af8524f3d896d05c171d62728",
            "abde0b9a6e5a4f509486ff68d20b9450",
            "8ca47341da314a3e9d3bedcb148df3e6",
            "7082db71bc2144478cd96fd2bd5f1000",
            "a6e01e95f0724204a921dc09f54cc121",
            "a1fd26d3b4ea406aa74b1b6478764033",
            "e37cb5d5d10b499d8072b76be4b5f0cc",
            "9faadf1780b747479a56f61fab0c0196",
            "17abd012f3b64d7492c37108fead8b0e",
            "0c62b0f69df94f50b1113f75e6d06040",
            "a681ecfdd3744c46b969e8697a0fb842",
            "3e40eeb0165d48de84b8a6a9e0982394",
            "28f98f9afcaa45c38f28167088752603",
            "7d46d34beb334c8f8c746b570fe39646",
            "367d476be0eb4f999474b9d2e56e5c11",
            "d3f719b0c74b49e1837b33164a94ef6d",
            "e00736526f4849b68ef1a0512f544ecc",
            "56464eb22a5c4f7990fcb108827e7858",
            "c979a44f8f464a6a9827fa8fbe37b5fc",
            "83d32720dd0f4565a68a4b948aeff600",
            "824f3b6c85e7405e9d43c531dd62f0fe",
            "f30fe4420c8a4bb186426628c462267c",
            "8d8e9e8495254f74a747ccb449533761",
            "3a7891784e4e46fd83cf674812674b57",
            "71870799819b4d2e846f222fcbd36078",
            "b5c3a4ad9cb64dddb4859638ab2c84e4",
            "ebac6847c5734786800b40344864acf9",
            "abd761c99de248f0b5a9f0d69631da4f",
            "b54f02a532da421cb797aca3308a6739",
            "44638fb0106141698037a5e7c278f105",
            "fc893326cfd44e17826387291205d9f4",
            "7fa0e5eef38a4dd4baf3ad680893026b",
            "2a85ea5f6d604d8a951d70d49a387823",
            "56f902be1a7849f29c51e63ae9c4c207",
            "4c066f745d034df8ba54bd17c4342944",
            "417dd943b6ba4c20b49cde8062eb00b8",
            "ce3d6219174a480587eecd5579ca22e6",
            "94a18cbdf9884bcd86cd57ec96725226",
            "a2ff77cf98b84898b24ea3ad141706cf",
            "7d812206c7854cf2835c5528eec08810",
            "63b6889df3114df8becc4915f55e61b1",
            "9c3b9be83a804450b66129866977352a",
            "9bfd775909a14f4984055e3067296d4a",
            "857824390af947648503a91d85b5b314",
            "8f2f6e6be6f24490982746bd842c6cd6",
            "67924f8df7e44df581dd85904a83827a",
            "45b8e3b11a7e40fb810981cc022feb31",
            "420c2cbd6503440893f555b900248886",
            "1e673475bd8143099db9c873d6651b57",
            "6f2adbadf6d642f5b6ead60b00596b21",
            "0bf6a173f59647299fac15212a36c2db",
            "6eb2d9a9697d4f7091ca128691adddda",
            "a5a368db7612424dbb3f23504641d1ba",
            "07bf4d5248ed4378a435311772e34c78",
            "effdf579bb5f4441adbcbd32546ef8ee",
            "d87c40f6fee048538706a8f497291318",
            "fda9fd50f2534ac6bf916391a0d071a5",
            "3f7e62cde344483eadc7a908d80fa192",
            "d8925137fb444396a1da3567a94455f2",
            "6965751e359f459e890fcf6a2aaa7669",
            "27fba848287647e7910427237454a716",
            "5391ea3c7a0948dfba39a7b5a9edf3f0",
            "ad9f571be96f4a21a1662ab40c5c8d81",
            "1cfdbb390fee4bf7b434d025b5481fe9",
            "718837865a27439f8386c35281078091",
            "70d5a84d29e4459d9b44d1a7d01e8155",
            "51211c4e33e240279f61557cdf3a5493",
            "b15cbfef6a8245f0a6a3cf56bb613d49",
            "e71845b44d9e4ee6bcd692f32a86dae4",
            "2fab34b5bb054031b8142920c21cfa26",
            "ca4f3cd872a140a3a9e3d9b8ee27d42b",
            "4ea81a416b3142ec9e44b99eeec30227"
          ]
        },
        "id": "tooKStXZfQVY",
        "outputId": "bfcc6d89-aa00-4b93-873b-ae814a89a306"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/165k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e408150039564f17a259bbfa11b89056"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/6.27M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d03919aa3a15406ab30f185c312190e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e37cb5d5d10b499d8072b76be4b5f0cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56464eb22a5c4f7990fcb108827e7858"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add pad token = ['<｜▁pad▁｜>'] to the tokenizer\n",
            "<｜▁pad▁｜>:2\n",
            "Add image token = ['<image>'] to the tokenizer\n",
            "<image>:128815\n",
            "Add grounding-related tokens = ['<|ref|>', '<|/ref|>', '<|det|>', '<|/det|>', '<|grounding|>'] to the tokenizer with input_ids\n",
            "<|ref|>:128816\n",
            "<|/ref|>:128817\n",
            "<|det|>:128818\n",
            "<|/det|>:128819\n",
            "<|grounding|>:128820\n",
            "Add chat tokens = ['<|User|>', '<|Assistant|>'] to the tokenizer with input_ids\n",
            "<|User|>:128821\n",
            "<|Assistant|>:128822\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/2.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b54f02a532da421cb797aca3308a6739"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/247k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d812206c7854cf2835c5528eec08810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bf6a173f59647299fac15212a36c2db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-000001.safetensors:   0%|          | 0.00/6.74G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5391ea3c7a0948dfba39a7b5a9edf3f0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### visual grounding"
      ],
      "metadata": {
        "id": "5tayqB1wf0a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<|ref|> and <|/ref|>** are designed specifically for the **object localization** feature."
      ],
      "metadata": {
        "id": "mHTup6Y4gjMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"<|User|>\",\n",
        "        \"content\": \"<image>\\n<|ref|>The giraffe at the back.<|/ref|>.\",\n",
        "        \"images\": [\"./images/visual_grounding_1.jpeg\"],\n",
        "    },\n",
        "    {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
        "]"
      ],
      "metadata": {
        "id": "LSkxMBLtgIIY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pil_images = load_pil_images(conversation)\n",
        "prepare_inputs = vl_chat_processor(\n",
        "    conversations=conversation,\n",
        "    images=pil_images,\n",
        "    force_batchify=True,\n",
        "    system_prompt=\"\"\n",
        ").to(vl_gpt.device)\n",
        "\n",
        "# run image encoder to get the image embeddings\n",
        "inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)"
      ],
      "metadata": {
        "id": "oYzxzdpTZ0MJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d8abc4-caa4-44ff-dcfd-6dcc655a53c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = vl_gpt.language.generate(\n",
        "    inputs_embeds=inputs_embeds,\n",
        "    attention_mask=prepare_inputs.attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    bos_token_id=tokenizer.bos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=False)\n",
        "print(f\"{prepare_inputs['sft_format'][0]}\", answer)"
      ],
      "metadata": {
        "id": "Fmvl9imYsH-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fb5faa-31ca-44b0-bcfe-922d6f05d561"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|User|>: <image>\n",
            "<|ref|>The giraffe at the back.<|/ref|>.\n",
            "\n",
            "<|Assistant|>: <|ref|>The giraffe at the back.<|/ref|><|det|>[[580, 270, 999, 900]]<|/det|><｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### document/table/chart understanding"
      ],
      "metadata": {
        "id": "O6Yxxac_f_f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"<|User|>\",\n",
        "        \"content\": \" <image>\\n This image has one table. What are the columns in this table?\",\n",
        "        \"images\": [\"/content/invoice.webp\"],\n",
        "    },\n",
        "    {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
        "]"
      ],
      "metadata": {
        "id": "IY8uGxukgBP6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pil_images = load_pil_images(conversation)\n",
        "prepare_inputs = vl_chat_processor(\n",
        "    conversations=conversation,\n",
        "    images=pil_images,\n",
        "    force_batchify=True,\n",
        "    system_prompt=\"\"\n",
        ").to(vl_gpt.device)\n",
        "\n",
        "# run image encoder to get the image embeddings\n",
        "inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
        "\n",
        "outputs = vl_gpt.language.generate(\n",
        "    inputs_embeds=inputs_embeds,\n",
        "    attention_mask=prepare_inputs.attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    bos_token_id=tokenizer.bos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=False)\n",
        "print(f\"{prepare_inputs['sft_format'][0]}\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-oMxmCWg7gX",
        "outputId": "4c09df19-bb46-49ad-c3d5-5bd73e7e1a8f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|User|>: <image>\n",
            " This image has one table. What are the columns in this table?\n",
            "\n",
            "<|Assistant|>: The table has the following columns: No., Description, Qty, Price, Total, Discount, Sub Total.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### OCR"
      ],
      "metadata": {
        "id": "jVHVlupUhr2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/content/captcha.png\")\n",
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "tH5bAAHdmjrq",
        "outputId": "58a0499f-a79b-44b9-f604-d8f8a1d41e55"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=200x50>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"<|User|>\",\n",
        "        \"content\": \" <image>\\n what are the characters mentioned in this image?\",\n",
        "        \"images\": [\"/content/captcha.png\"],\n",
        "    },\n",
        "    {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
        "]"
      ],
      "metadata": {
        "id": "5miWpj8qhuCq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pil_images = load_pil_images(conversation)\n",
        "prepare_inputs = vl_chat_processor(\n",
        "    conversations=conversation,\n",
        "    images=pil_images,\n",
        "    force_batchify=True,\n",
        "    system_prompt=\"\"\n",
        ").to(vl_gpt.device)\n",
        "\n",
        "# run image encoder to get the image embeddings\n",
        "inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
        "\n",
        "outputs = vl_gpt.language.generate(\n",
        "    inputs_embeds=inputs_embeds,\n",
        "    attention_mask=prepare_inputs.attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    bos_token_id=tokenizer.bos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=False)\n",
        "print(f\"{prepare_inputs['sft_format'][0]}\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wOTq1BahxpX",
        "outputId": "f427caff-b1bc-4c40-f811-7bb27786a6c1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|User|>: <image>\n",
            " what are the characters mentioned in this image?\n",
            "\n",
            "<|Assistant|>: Zenf4<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### multiple images/interleaved image-text"
      ],
      "metadata": {
        "id": "sDqSkNMvnsAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"<|User|>\",\n",
        "        \"content\": \"This is image_1: <image>\\n\"\n",
        "                   \"This is image_2: <image>\\n Can you tell me what are in the images?\",\n",
        "        \"images\": [\n",
        "            \"/content/image_1.jpg\",\n",
        "            \"/content/image_2.jpg\",\n",
        "        ],\n",
        "    },\n",
        "    {\"role\": \"<|Assistant|>\", \"content\": \"\"}\n",
        "]"
      ],
      "metadata": {
        "id": "ockGJOG1nqon"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pil_images = load_pil_images(conversation)\n",
        "prepare_inputs = vl_chat_processor(\n",
        "    conversations=conversation,\n",
        "    images=pil_images,\n",
        "    force_batchify=True,\n",
        "    system_prompt=\"\"\n",
        ").to(vl_gpt.device)\n",
        "\n",
        "# run image encoder to get the image embeddings\n",
        "inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
        "\n",
        "outputs = vl_gpt.language.generate(\n",
        "    inputs_embeds=inputs_embeds,\n",
        "    attention_mask=prepare_inputs.attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    bos_token_id=tokenizer.bos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=False)\n",
        "print(f\"{prepare_inputs['sft_format'][0]}\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "382vf0twvSpz",
        "outputId": "61a564b9-6620-487b-81a8-2b8c20491dd8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|User|>: This is image_1: <image>\n",
            "This is image_2: <image>\n",
            " Can you tell me what are in the images?\n",
            "\n",
            "<|Assistant|>: The images depict a rural roadside scene. In the first image, there is a small roadside stall with a blue tarp roof, displaying a variety of fruits, likely coconuts, for sale. There are three people near the stall, with one sitting on a bench and two standing. The second image shows a road with a red auto-rickshaw and a white bus driving on it. The bus has a sign in a non-English script, possibly Sinhala, indicating it might be in Sri Lanka.<｜end▁of▁sentence｜>\n"
          ]
        }
      ]
    }
  ]
}
