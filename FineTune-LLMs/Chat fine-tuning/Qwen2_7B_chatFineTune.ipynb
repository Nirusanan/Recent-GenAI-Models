{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpjGtCmVu1OM",
        "outputId": "de166e7e-b7a7-49ea-c1d9-82a325b92125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.7/316.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q \"transformers==4.45.2\" \"datasets==3.0.1\" \"peft==0.13.0\" \"accelerate==1.0.0\" \"bitsandbytes==0.44.1\" \"trl==0.11.2\" \"safetensors==0.4.5\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"Qwen/Qwen2-7B\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"cuda:0\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893,
          "referenced_widgets": [
            "cc76e905245c46549a99fefe860cc2fb",
            "09d8bc319f884df19d31b991e07df906",
            "0da9033a4adb4193b6b6580a1284077f",
            "2cb5447a43c145e5b3e284ebf2fcad00",
            "b4afc8eead1549daa585b321313acda2",
            "80ccb38d1b0647d4aa5feef9ac83485c",
            "8102caa574a14963a24728f41ef59f0f",
            "d97324a0f7d84f42b6f0beb35614fb32",
            "68cdaac4baea4a2d9e3391d80d8890a3",
            "4c00a7c924234c8f9f737f9156c6461e",
            "cce0cb954b514487bd6b05f609eac518",
            "75341e40ff9c43b58c6a87a457374d98",
            "6f6d3bd9a01247459e94fa1e36377257",
            "0c9e5befd80b45298205a584916fdb8c",
            "b41f743f8f4a423bbcdef4a2b87f21ff",
            "729eb276448d4879b36df0b20d8950fe",
            "da0187c4d981419f82116aa9487ed4ad",
            "3f73fc7f2af44ea3bb3237f7f4678686",
            "b08b1a29ac834d0eabe93bb5f4cd11ae",
            "3db13d70b301465b88c4a33aa5294d62",
            "f782667941574cd2982b3476553f5473",
            "67e08a0f02844677a19618dccaee15bc",
            "84e5949a2f4e41a6ac977998d5921034",
            "573877c4b1884d08baf6853c18798850",
            "f129c6381a9e493788b66d76918f4115",
            "9ad8ea7ee15748d896273cdf5ea8594a",
            "6133b2ca042b44b9996de5dd3c5ef0a7",
            "b31fc6952faa4745a6a1b46ed08bcf46",
            "1d3d0ba8a5244b7fbdce10a9cc3c125c",
            "8bfbfc63ca8f44ab839c1414b0939dfe",
            "d18fa53d66db419aaea92ee05d4ddd4f",
            "0fac4f38268d45a99d96abb9444c1f23",
            "99b231b5e66d4224850650b7b1b81217",
            "b8750c9783ab4189afe1ec2eb2950a2d",
            "8b43ddbe600d4f0d9250ffa4715e0531",
            "025517bdb1aa45ad85ce84ac19f3b4b0",
            "76fdb77bf68d427795644324b38c440a",
            "59655bbe609e4eae9f0c194b024c0920",
            "e36941576fb14ac397db1168696db45a",
            "d95278c84cb2406ebd5559ec35af16de",
            "f06c4265461042c5ba6d87b62c1f8b0c",
            "501fa804b121490983245c47aeefded1",
            "78729d0be7b04d7789adf20c64722868",
            "69e3d5e6dc244d3cbddadbbf1c1ea5db",
            "5e9330331c8446699761c7e136820ae4",
            "3a688812c80a43d6a8a6438614eb01f7",
            "4e543669a63c4691bd8afba35b1c034d",
            "bb140b6a682640608e52d3fcb7b6e90a",
            "5be348fe4c404594a6338548f6efd1ad",
            "54527a261e6d4835a202c01919037510",
            "02408d1234754c60a896dd87a59855d9",
            "775c3fbc16ad4d469a702279b6a3f4e4",
            "483496850d48467589ddc8b18124acd8",
            "d0e7427b66f545ccb88b4154f24fa2e2",
            "508f96c1abc34e2dbd20fe2f6705ef5a",
            "75bb19658c0641738300f65c1fcac48c",
            "ba65c8543f044b69bae8dff33d965da1",
            "e734e6b6703e4e8691ddae14dbefe397",
            "ff42ccf9985c4c2e8fb2d5593f903278",
            "c94eaf700d7d47a2877ae9158f56cdbc",
            "3ba2e35e849d4e679c15d14cfdcb5ec9",
            "6a2431ddb2d24052be1a2962f6dbe576",
            "00dc6b38d6544f3da8d3b70f4f1c85cf",
            "34e698a89853408e99d9bf7e43e4754e",
            "43e46c6963fd4597b5928234565d7455",
            "bce5075a78844da397f1df70547bdb4a",
            "3da961fb21eb453da81ad988e2d02578",
            "14dada30c66043619797bcb674788dcc",
            "17b54e487e3c4e60a1251823b35b7459",
            "68ab632df6a249048adc80603322e4bb",
            "7367d1d2a8a04c0fadd9390f23101bed",
            "d2d29d571c4e4522bb7948727b7631d1",
            "207c1f848c8644d996caa71ce02e1b58",
            "4eaf3900ce6e490ba42d56f1c66b3747",
            "53f805fbd728402a855079afea4bc2da",
            "9c9c0067c3bc44f886958e6c3f992091",
            "b6af091c25b54dea914e510802187b90",
            "f8756cfd45c849f49d1654d22b785b67",
            "5a624420952e42ed8cb75511c6c1fcdf",
            "10e12cfdeab445a9a231b0f25db48ee6",
            "916be1741ae64a838fa9510fd9cc78c4",
            "f8e8aa19263f4ffe81f8ee3355a7cd73",
            "25993f154e334bdd89ce8dd9ffd951a4",
            "7896853135d1404b81a1c0ceafa28075",
            "6aa304b7f3b54c83851b451c79f92cf8",
            "76cc837b92ec4045952adb845ab81a9d",
            "931cc56ad84749bcb8c6d5039b0aea96",
            "e4e48ad4a1a84609bfd536e5d21be947",
            "854d5626bf124937b7c68a692e89d746",
            "d6bcdb4fa1b14242a2d278689b81cbd9",
            "dce4f651907647c48cd45bb15e6cdf52",
            "9488abc5c3de471f934a54c71c236ff1",
            "6fd85c514c584d3882785dd3ee85f9b7",
            "136228cc5c3544a19cee0dcfbbe446fc",
            "79462d2c4ded460a933813842d76b872",
            "2b467c35ec014275b4325b6f113a188e",
            "4e00111702a74313a947e077c69f062a",
            "67cb97a066ff4ead910f95ac1718af76",
            "3adbceb676cb4728860b32ef946aa446",
            "1560faa4c1274ea5b848b16481361de0",
            "40f640d125c04299a8883f87fe16601a",
            "f2f3a7ada74845e9a0896eee6ac1bd27",
            "2583ae89583448e2b13e00d8f28af322",
            "b5f3368480284789a94a7ac5c95cc5bc",
            "58be65528d784f3a811d08ba25437640",
            "dadeb6883e3244f5899158859a5f8d33",
            "b8fdfc735d94410eac43cda6644f2e16",
            "50a3a3d32cd9463f9dbe7d7796c526f0",
            "2bac6dee082a4e9ba933b21d104c9a4a",
            "89052570aab4405f88a3e3ee6f7a4d64",
            "45ce2d41a5834f909c52acefd105ba0a",
            "5f01e95ec6fe41f39f5cda72c9a84a01",
            "cc8446a2785943cbb8294c5260950a00",
            "4c0333dd313c4ae49ab7bcd6a2296272",
            "e1190ac01e1d4619bff6465c418f777f",
            "0bff40a9117a41979ac4a308f913fea8",
            "3cc14e8ebb8d49b89212b6afee9043b4",
            "c4db23d5458043478a3f7dfdd2610c20",
            "6e9a2016a7874bbf9fd0fb48d95a70be",
            "bddb7941726145658763db8aacb48382",
            "b195806d31f64b8c85bc892fe434c2f0",
            "44465f7c428a427cad133255253e045e",
            "80e7f9bbd8a543a3a515da712f865e6a",
            "e4555dec28664bc7b27bf67671a748de",
            "9252df579c25418f81b3ca9ef47fe175",
            "0690c9ecec7747278cf6716c292a88e6",
            "2cc42bdf7ccf4433b61e526e5b5ffc67",
            "f69b27b33ff14d1ba29c1bb08d8f4305",
            "b0ff69283721467d9b08a3d6df3f5407",
            "ae4ea50baa194af096afcca27c4effcf",
            "96d0a22f5b8e47eeaf84027084911f41",
            "9a2668a7b7e849cfb4e29cf25e216fb2",
            "6460be12ecd2435fafd058deeb821bc6",
            "d20e402de26240c8a2b10e99c399c326",
            "96b06abcc30446acbce90042b9a64ccd",
            "db7c26c754ab4f188b1bebd332b31912",
            "c3bdb033292842e697194267a682ef2b",
            "9f97520fff4245fb912402ec931096ef",
            "7ceca64e9b0e4758a52ae60f256d6492",
            "c37cb67f39d44f72a43024ab8f0b3707",
            "a2d2c7d070b4442bb2e44d393d2397d4",
            "7ba782d4300547f883eca9dea39fa5a8",
            "ddf8526a1ccc42f8a950098aa4095d58"
          ]
        },
        "id": "VmPvAoGLu1nH",
        "outputId": "682655f6-5611-46f6-a487-762b9ba2b02d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc76e905245c46549a99fefe860cc2fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75341e40ff9c43b58c6a87a457374d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84e5949a2f4e41a6ac977998d5921034"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8750c9783ab4189afe1ec2eb2950a2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e9330331c8446699761c7e136820ae4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75bb19658c0641738300f65c1fcac48c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3da961fb21eb453da81ad988e2d02578"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8756cfd45c849f49d1654d22b785b67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "854d5626bf124937b7c68a692e89d746"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1560faa4c1274ea5b848b16481361de0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45ce2d41a5834f909c52acefd105ba0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44465f7c428a427cad133255253e045e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6460be12ecd2435fafd058deeb821bc6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"train_sft\")"
      ],
      "metadata": {
        "id": "F_r1JGSDvHha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797,
          "referenced_widgets": [
            "c04ba5707e2343718d6f96bff1479ad8",
            "dd6e275f83ec4cd991621e3ae60372ec",
            "6edd74ede14a4a409ffbfd99f1fcf25c",
            "b9c6a424775d49fda23e7dea32f91747",
            "10db1c74e4a94fd0a1de68e5a3325028",
            "5721982b3d0842ec86cd11a93a5fbc54",
            "23f98806c64b46a88d9da744574dabf6",
            "8c1085d5a8124e4c8cc23aaada0e7d56",
            "87626d3abc2f4c3caa32c0362c2c6552",
            "1fcfa0b360aa46cba430c937c5de552b",
            "a6d3f1fc82774ec0a3215e71abb6eb46",
            "d4aa2b756993404088e70650ea278b40",
            "582b092b8b5f47d684d0873dd0df3db7",
            "55403c05828240c2842ca42ac6694296",
            "fbda23e7dfb74cfaad3183ca0910e0d7",
            "9293fd7809d649429e79864ebfe29189",
            "e66fea98e2b84370840dd631b32401e8",
            "aad13f345aa64127babea03ef11e3518",
            "466831e49c1646b2b2c3ee1981f64569",
            "4f59e109c6b24c6687885b0fb55bce04",
            "c2a41ebaade84444bb79a1c987b37ac6",
            "155293eb72a1465da2e2d6fb9da144a7",
            "d727795f55b04f1f82056733da9ecce5",
            "4367d8cf03f445efb0c247ca156916eb",
            "44338369758c4f99b7186f2d2ef68390",
            "e758bbf6bded4cfbb91b4a857e10488e",
            "0e4c417ccdde40b7bbea40629737c3ba",
            "568ca2c3e1614420bd9596d34909f52e",
            "3f2575ac80f349b789e1eeb76a4f5ae5",
            "e466875a1f0845c2a70723188e7cabea",
            "e0f48ed0de5e4e619c65557a4a64d67f",
            "1a09113bfdda481b990dfe64532ab7f9",
            "81356de4addd49a1944ee574a9742fba",
            "7bba15f7053b4118af3850dad7d8d8ea",
            "d4d38c267d6346359175c3e342580801",
            "f38f92e6991f41bab25e76d123976444",
            "c62f24fb32054b6ab78341753cd60176",
            "a20fbaa827e04890a9426594d7dbf87b",
            "99ad9132bf5446d2a82f84c0ef5f2cca",
            "45b7d1759e694b13bbed899692899cd6",
            "e3c98d44bcd34cba9b54b989ee3e2314",
            "190951c2d178422a8ded0eb5cb259916",
            "3bebdd18862246bfb6e0d686736d83f7",
            "67127de1aeb346c4bb581ff14844333d",
            "935dd014f6db4c5bbb6e9cbc78f5f12b",
            "51cf1e68df3c49d58401d862532f7ac2",
            "220156430d88462383b6181024516c1c",
            "f81066b656754fa596c574ecedc4d16b",
            "2f0f3bac0502465b8f89a4c1e2ad78fa",
            "6311bdc166e2427f98a5dfffc479ab69",
            "96dfb102dfb646f1844ba803e93f0b83",
            "69b8a3b976b84f57b4d8e16cb178ec45",
            "5cc106484e534f8db9fd39dc25c59276",
            "6747f86a55644dbe9dd859dad7dbfcb6",
            "712fdffda85d40d38edb46ae8bf74c6e",
            "c418f23c27774b8089ed096865346d94",
            "d90d0f183e6c4b3faf1ef0f7567b2383",
            "c8518bc62eea421b814d4707c53ba300",
            "5ecf2386cb3041fe8fbbf85d24489571",
            "d42dd12787354280a6b1ff011c0b3628",
            "972cdfaaaa3e4b53ba0d723953724f83",
            "234a92facad245b3986ff0903e159d4c",
            "f39776a8bb504e448c0fee6e30056f86",
            "2b4d186e495d4609b3845ec7478f12a1",
            "3277e2d8d48f4031b9d2833438475c99",
            "f63a47df99174cfeb8008a0be250807b",
            "48d912f20ecc4d7f8ed5fbffc89e5e34",
            "470ed97f6da04bc7ac1d233fe376e2f6",
            "831a944fb39a4efca9667ef3d58ed66c",
            "760f6b697cbb4128a1e990c1b9162913",
            "56414561b84546b4b0b39e168e73badd",
            "974a6f769d834fb3939dca68f9f1eb32",
            "fc1a1c66ad01433188654964d5888eb3",
            "4b84b12e6d1c4a87b338551688894bf1",
            "9cb7451df6cf497a9b5851d36317459c",
            "f91a9e1578364fe5866f2e88d9cfd644",
            "8810aecf6ab84174a8c4233ec4f986b9",
            "5447c470ce4d43fab274786207682983",
            "621b1f696e15426e8758ade1d810a571",
            "310a86790462429cbc2409c076c40d50",
            "c75275495c4a4f3585f89eba09fdc7ec",
            "8bae33a240ad45fd9d2a1e55a4ba9c1e",
            "816f08e696ff45db87087c29dad93138",
            "91c4853fc60543eca699ca6e1ec5aa9c",
            "29937422bcc94fb5a5be4863b60b15ff",
            "f5068e8cf6c44cdbbec312e8097debaf",
            "8a8abfd1aaf44d5dbcf4357fe2c79f9b",
            "7f40bef807e846fd9808d7a8587e4588",
            "a432f0ea7f854561a05c7c119b354095",
            "8992acdcaf4a4241861fd5491d889587",
            "b934284f4e024c83a55b1f0118951a98",
            "8c9d768b07f440d6bd3d3ee002fb3f5a",
            "f429755f56764b7aa54f08e7b513a46b",
            "39a38236a74c40eb9dd6212b310936da",
            "a2d622d8986d40f39a9cdbf3da6322b9",
            "ee6383708e3f47f18373f21fe69605ac",
            "91165fc525f64aeaa9755574801c7209",
            "069d7ad4fbc54a3aab246a64d7aa2f91",
            "caef5e701ab7430f92f263f32995826c",
            "1904404ece8147bea9487cfda1113e8f",
            "17e2bb2e6d11497b9cad67e8bfdbd906",
            "4581b1b2f0b045f0a2a51db9b1066947",
            "01aa30ac8cff488f95b4e6055178b329",
            "fb3789a08e4641f2bbdbeb2bd0541ef5",
            "d5897be64cae4db998595800d92a4d5d",
            "e842f03d0d374504bce9d599abb73937",
            "37d792e141f840bda8f5189e02b3be96",
            "253b4aa5f0114bf1abfe6437a14f5b9a",
            "ef5efb9bad514afca6b8c04e0822be38",
            "d80bbe0c735a499fb47d7160d541b198",
            "c6fbf015bb624fa3b0fbcb7146e7f681",
            "4b33d7b202a74bbdb1bf0fe4c12d3cf8",
            "8168005e4a644ef19da07ce9ba3da0b0",
            "89ed53cff82d4306baee697570bdce24",
            "b9a13fa2746142e7a7a38f6e94798026",
            "6d239394045e409491ca24f61ef0005b",
            "e96c1e42e4c64069b76e1e8491644687",
            "e0dd1610b7f44fdbb37cb52ee0320ab5",
            "5dda89aadda04640ac74a1fef13d13b6",
            "d65a1adbc0774033b5fe5a5b40bba59a",
            "019389a7e60f4940a36d22f1e839389e",
            "76ce08b569a04e17889c75e0289ba4f2",
            "3c91b4e6d6174be285bf0e8caa250ec0",
            "a03fdd2fd4ae4ae097d752a56a98045c",
            "cb52299f75f442b48f719c9da6d38a62",
            "181e3d744238447696a497418f68e2ed",
            "10ad0c365a824aa5a0b29d81d591942c",
            "b57cb9c123cc4ef9bc559e6d21072e0d",
            "4783ce1e1a054bbeabbf1747a87a5d7a",
            "09e0eabb3dc54317892c9e4fd18e7da2",
            "f6a3fb249f7244de92d95413f7f165fd",
            "7ac717394551466d9d87fab9e5f3131b",
            "8497bf955a6f4aeda75e20159d570c3e",
            "2ab7b88b635f4bacb70a7f04cb36cbbb",
            "8ff3c5e275524f1fb097cccc688a5600",
            "0e358caaf5554e3d84b6ecd1bd3ff62a",
            "cff71521fca5406799f9f9efe0c6fca5",
            "f4d0f21c414b47f0905daccfa27e2c94",
            "6ecbfb59eb2845b4b957472408ff1a2c",
            "e143a3ede33343709c8a9bcd85d25afd",
            "249e329b2e11461fb0e62778ad5e9be5",
            "17862953d559428782dda274540e3fca",
            "dbc332f993f24e609e9544590090c6e1"
          ]
        },
        "outputId": "865d7b6c-bc20-450a-b87b-2f3fea5bd394"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.44k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c04ba5707e2343718d6f96bff1479ad8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00003-a3ecf92756993583.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4aa2b756993404088e70650ea278b40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00001-of-00003-0a1804bcb6ae68c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d727795f55b04f1f82056733da9ecce5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00002-of-00003-ee46ed25cfae92c6.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bba15f7053b4118af3850dad7d8d8ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-f7dfac4afe5b93f4.parquet:   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "935dd014f6db4c5bbb6e9cbc78f5f12b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00003-a6c9fb894be3e50b.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c418f23c27774b8089ed096865346d94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00001-of-00003-d6a0402e417f35ca.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48d912f20ecc4d7f8ed5fbffc89e5e34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00002-of-00003-c0db75b92a2f48fd.parquet:   0%|          | 0.00/243M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5447c470ce4d43fab274786207682983"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-3d4cd8309148a71f.parquet:   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a432f0ea7f854561a05c7c119b354095"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train_sft split:   0%|          | 0/207865 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1904404ece8147bea9487cfda1113e8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test_sft split:   0%|          | 0/23110 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6fbf015bb624fa3b0fbcb7146e7f681"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train_gen split:   0%|          | 0/256032 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76ce08b569a04e17889c75e0289ba4f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test_gen split:   0%|          | 0/28304 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8497bf955a6f4aeda75e20159d570c3e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template = {\n",
        "  \"chat_template\": \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|start|>system\\nYou are a helpful assistant.<|end|>\\n' }}{% endif %}{{'<|start|>' + message['role'] + '\\n' + message['content'] + '<|end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|start|>assistant\\n' }}{% endif %}\",\n",
        "\n",
        "}\n",
        "\n",
        "tokenizer.chat_template = chat_template[\"chat_template\"]"
      ],
      "metadata": {
        "id": "_7qNr8IrvHlb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jinja2 import Template\n",
        "\n",
        "def apply_template_to_dataset(dataset, jinja_template_string, add_generation_prompt=False):\n",
        "    # Create a Jinja2 Template object\n",
        "    template = Template(jinja_template_string)\n",
        "\n",
        "    # Define eos_token and bos_token\n",
        "    eos_token = \"<|endoftext|>\"  # This is a common end of sequence token, adjust if needed\n",
        "    bos_token = \"<|im_start|>\"   # This is a common beginning of sequence token, adjust if needed\n",
        "\n",
        "    def apply_template(example):\n",
        "        # Render the template with the current example\n",
        "        rendered = template.render(\n",
        "            messages=example['messages'],\n",
        "            add_generation_prompt=add_generation_prompt,\n",
        "            eos_token=eos_token,\n",
        "            bos_token=bos_token,\n",
        "            tools=None  # Add this if your template uses it\n",
        "        )\n",
        "\n",
        "        return { \"text\": rendered }\n",
        "\n",
        "    # Apply the template to each example in the dataset\n",
        "    return dataset.map(apply_template)"
      ],
      "metadata": {
        "id": "chq9aE73vHox"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dataset = apply_template_to_dataset(ds, tokenizer.chat_template, add_generation_prompt=True)"
      ],
      "metadata": {
        "id": "_dajusYUvHr6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "8f47e740898d40a28c68b26ef8a90fe2",
            "34d9827f27df47c685d76737bcbef37b",
            "d2152017a0da4a0a9e1c95dc35354677",
            "305d5d12e06f4cb3a8efe8c101fc31cd",
            "3dbd0b2e4ad54e0d9bbffc6b49f4dd4a",
            "cdc0f5a8146f46aabd9e7a0bde6aa61b",
            "22de1bbcabce4ac3973f58228de984ac",
            "7b657e14a9ec4f2987cbd785acf9e41c",
            "c529af3311d146eb965ef6e9c99f00b6",
            "06bcfd25d2f3405cba191660d007a23f",
            "d33b799d6a1b477ba7e39b6bdf252c3d"
          ]
        },
        "outputId": "bb6f9a0e-f38d-4d3f-88b6-51a377112ad6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/207865 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f47e740898d40a28c68b26ef8a90fe2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(processed_dataset[\"text\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFRO1t_4u1qK",
        "outputId": "eb269e9e-2f32-4581-d310-5581cf0867e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|start|>system\n",
            "You are a helpful assistant.<|end|>\n",
            "<|start|>user\n",
            "These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
            "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
            "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
            "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?<|end|>\n",
            "<|start|>assistant\n",
            "This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.<|end|>\n",
            "<|start|>user\n",
            "Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?<|end|>\n",
            "<|start|>assistant\n",
            "Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
            "\n",
            "1. Log in to your Shopify account and go to your Online Store.\n",
            "2. Click on Customize theme for the section-based theme you are using.\n",
            "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
            "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
            "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
            "6. If available, select 'Show secondary image on hover'.\n",
            "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
            "\n",
            "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.<|end|>\n",
            "<|start|>user\n",
            "Can you provide me with a link to the documentation for my theme?<|end|>\n",
            "<|start|>assistant\n",
            "I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.<|end|>\n",
            "<|start|>user\n",
            "Can you confirm if this feature also works for the Quick Shop section of my theme?<|end|>\n",
            "<|start|>assistant\n",
            "The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
            "\n",
            "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.<|end|>\n",
            "<|start|>assistant\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "lora_config = LoraConfig(\n",
        "    r=64,\n",
        "    lora_alpha=32,\n",
        "    target_modules=['o_proj', 'q_proj', 'up_proj', 'v_proj', 'k_proj', 'down_proj', 'gate_proj'],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "qKiFqUeku1tb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable, total = model.get_nb_trainable_parameters()\n",
        "print(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U-d2o-0u1wL",
        "outputId": "ad76ff45-f41b-42c6-be6b-48777541be30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable: 161480704 | total: 7777097216 | Percentage: 2.0764%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from trl import SFTTrainer\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=processed_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    peft_config=lora_config,\n",
        "    max_seq_length=2048,\n",
        "    args=transformers.TrainingArguments(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        max_steps=100,\n",
        "        learning_rate=2e-4,\n",
        "        logging_steps=5,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        save_strategy=\"epoch\",\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "464bbda040694e37b07521b78374d894",
            "e15ce8b507304c998569e7bbd1457cc2",
            "149fa7f3be1541d49a5b7ff2385ddcac",
            "374d80c4064c463c896a43af4ff50238",
            "44e4e21005e74252919ab3aedf8065fd",
            "cb8767ffc8fc41ce88c1ca6313214d9a",
            "c0cc8cc0a75c4777b7dd1b21a5dba187",
            "143a02aa46b341d6979c50b8d7332421",
            "8d9fbd5c39d6425196565d9a9eea66d9",
            "fa64ed39b1a3489797a10763eb3c24ab",
            "39a0a93c792442598d33328c4b5e3fad"
          ]
        },
        "id": "tgGZtdgku1zq",
        "outputId": "cd1b4ebd-c3a8-4ebd-f9cc-5470b7485323"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/207865 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "464bbda040694e37b07521b78374d894"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 03:23, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.056900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.931200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.948900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.991000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.182200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.257600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.038700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.241400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.243600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.132300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.106200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.051700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.197900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.115700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.102000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.067900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.137500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=1.0937612390518188, metrics={'train_runtime': 207.8037, 'train_samples_per_second': 1.925, 'train_steps_per_second': 0.481, 'total_flos': 2.099989169800704e+16, 'train_loss': 1.0937612390518188, 'epoch': 0.0019243258845885551})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
        "    {\"role\": \"user\", \"content\": \"my name is Niru\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Nice to meet you Niru\"},\n",
        "    {\"role\": \"user\", \"content\": \"write pytorch LSTM model to forecasting\"}\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "print(text)\n",
        "\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')\n",
        "\n",
        "# Define stop token\n",
        "stop_token = 151645\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=250,\n",
        "    eos_token_id=stop_token,  # Add this line to use the stop token\n",
        "    pad_token_id=stop_token  # This ensures padding doesn't continue generation\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sASgW32Cu2T1",
        "outputId": "c7cea286-c086-45b5-d3f0-645df2909b40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|start|>system\n",
            "You are a helpful assistant<|end|>\n",
            "<|start|>user\n",
            "my name is Niru<|end|>\n",
            "<|start|>assistant\n",
            "Nice to meet you Niru<|end|>\n",
            "<|start|>user\n",
            "write pytorch LSTM model to forecasting<|end|>\n",
            "<|start|>assistant\n",
            "\n",
            "Sure, here's an example of a simple LSTM model for forecasting using PyTorch:\n",
            "\n",
            "```python\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "\n",
            "class LSTMForecasting(nn.Module):\n",
            "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
            "        super(LSTMForecasting, self).__init__()\n",
            "        self.hidden_size = hidden_size\n",
            "        self.num_layers = num_layers\n",
            "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
            "        self.fc = nn.Linear(hidden_size, output_size)\n",
            "\n",
            "    def forward(self, x):\n",
            "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
            "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
            "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
            "        out = self.fc(out[:, -1, :])\n",
            "        return out\n",
            "```\n",
            "\n",
            "In this example, the `LSTMForecasting` class inherits from `nn.Module` and defines the LSTM model. The `__init__` method initializes the input size, hidden size, output size, and number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"qwen2_ultra_chat\")"
      ],
      "metadata": {
        "id": "nx_6emsE-pvE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_params_billion = total_params / 1e9\n",
        "print(f\"Total parameters: {total_params_billion:.2f} Billion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGQ2-1IK-zuy",
        "outputId": "f29382db-e6d8-48e6-c5cc-db18c7bfa92f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 4.51 Billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    \"/content/qwen2_ultra_chat\",\n",
        "    low_cpu_mem_usage=True,\n",
        "    device_map=\"cuda:0\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Merge LoRA and base model\n",
        "merged_model = model.merge_and_unload()\n",
        "\n",
        "total_params = sum(p.numel() for p in merged_model.parameters())\n",
        "total_params_billion = total_params / 1e9\n",
        "print(f\"Total parameters: {total_params_billion:.2f} Billion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94,
          "referenced_widgets": [
            "bd249da0abab45e9b54be58bd853e45c",
            "1de365a7f7de4224ae231d4a29529e39",
            "6efa4cbeac82447da5ae228773eeff8e",
            "4f946474fdf64a39bc4147be7e0ce05b",
            "fc56cc59239e418b871124f03fad9503",
            "563e288c9bb84ed3af848e4be0957dc9",
            "1f2eaade69084444b2923e87e6ad8925",
            "be31a84a9f2d4193b385ecfdbad55a79",
            "87b6dce431ac4870b0d0c20ccc57d431",
            "9e7a31f2b710420f908facaed4b92d64",
            "f56d7cb5cbac4e11a3c332471b21f070"
          ]
        },
        "id": "RD2EVHA2-zxz",
        "outputId": "585fa671-4e79-4f34-a039-5467ca76498d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd249da0abab45e9b54be58bd853e45c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 7.61 Billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(merged_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "Jbyv5R7rCLGU",
        "outputId": "a3d86eac-81fd-4c58-bdd8-7413c2bdc832"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.models.qwen2.modeling_qwen2.Qwen2ForCausalLM</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2/modeling_qwen2.py</a>The bare Qwen2 Model outputting raw hidden-states without any specific head on top.\n",
              "This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
              "library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
              "etc.)\n",
              "\n",
              "This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n",
              "Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n",
              "and behavior.\n",
              "\n",
              "Parameters:\n",
              "    config ([`Qwen2Config`]):\n",
              "        Model configuration class with all the parameters of the model. Initializing with a config file does not\n",
              "        load the weights associated with the model, only the configuration. Check out the\n",
              "        [`~PreTrainedModel.from_pretrained`] method to load the model weights.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1082);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "p-5oWyQc-z0h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=userdata.get('niru_hf_write'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QpSFLlA-p0k",
        "outputId": "db793807-2117-4dab-afbf-de031ae8ab6f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# push merged model to the hub\n",
        "merged_model.push_to_hub(\"qwen2_7b_ultra_chat\", private=True, safe_serialization=True)\n",
        "tokenizer.push_to_hub(\"qwen2_7b_ultra_chat\", private=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524,
          "referenced_widgets": [
            "fafbb2e78a5f4d3d9bef625709775cec",
            "8e16f3b0479e48ccb9b1c3bde55ae0f9",
            "86ef44bb7af443a0aa79e789f1c91eda",
            "03d72b0557794ec4a066c4f12f296a80",
            "50f80303d46a433c8059b433e3927838",
            "cb9efa75a5704dd1af167fb692bb08de",
            "071517598b0843fd8b3900f6ed7d9379",
            "9d2d559bb9994bf1bad0dfa65cc084e9",
            "a2c1dee14e014221ab983d5ef3571cdc",
            "1645f747aad645b7997963b41fb1d70d",
            "7d51973034884059a2427ff61d7a748f",
            "cfd4026a5b83496e92778c12e58e45a2",
            "69e62782bf5c4baa9a2ac6cfc59fb417",
            "2439c52f29c341d2b75b50c1946a999c",
            "162141d73cf94922be28b6bd5553ebee",
            "c20127b9630a4ef7abfd04cdb53555f8",
            "c8b96929f379452899da4c0ad877e287",
            "062c4ef92f754f22861d3328d96bf6fe",
            "db28e22c65654919be2c19fc511fb0b4",
            "0565e5e546844cc4ade35fd4ca5104ba",
            "8f726d1170784729b0b455c7fe0f25f2",
            "0d826c9421d04dfa8525a57810df7d6f",
            "d61c88ecddf44edc9dcf667c251a51ce",
            "97c0a933504c4d9f9e339e547e0bd345",
            "272d8f8925e248048feec9d04b8b0144",
            "f34f1f02ec4b4b4aae559ff51116330f",
            "f388f12a9f1f4e0dafc025fe0d4cb2b3",
            "9a637f346f784447a9e5c7874ad61647",
            "1f345f1b92e047c9a5c493a1524a2231",
            "9ef5373b43024782b9834a5817ffa460",
            "4726a8ac12d74e169f21be1bea824a5f",
            "f2f890d0373446808415eba4f72c4309",
            "01754323708f4e6ca3d4cc20a4b3e0c7",
            "2f70acbfa79d42dab9dc5363d0959f7e",
            "421ba1540349492787e22765a8ce9cc2",
            "f0f4e6b99f664d6e9be936fd83b9a9bb",
            "ca91cfa097a947ac810a38848ce72f9b",
            "26b6830e772f4603bb68ada1267c0485",
            "bf420893d0e944afacdbf2c3d2ffae56",
            "d0aac4056e074aa48772c814c9c4fe03",
            "ac6495dbf233431c8feddbe47d719ffe",
            "3efad515e66143fab600bf23832bdb16",
            "288c3817503643e5b5f45ff23a325fe8",
            "90fab1b597774a34b991e055b88fcdde",
            "9d24d6214f0942078184e365d45e1f80",
            "d33fb79669974966854f649e5545a5a1",
            "2ea5c9c143534ea4873d1b71f4ab7fdb",
            "9eb63bc8aa4e470bac9ddaca0ad63f42",
            "b560e233295647b984779f44026ef7b7",
            "207bb35be046424696df97b0933e094c",
            "f278ca042b44428db038a38c4f00fbb0",
            "58f5077736ff471cbd197acd8342e472",
            "c65e6479ba634012b903984aad28acad",
            "9918dd424d384c97b323ecc0adc9ef7d",
            "6af22a4ca5134045ab6bce4e51db9016",
            "da926cfe684a4d51b5696403d85e684b",
            "d78085ee677d4373a34dbe81393751cd",
            "2a9b6ed18bab45ca8609b38e89c895ac",
            "c6e11501b9d3417cb35b4cb38105df9a",
            "efdc9b6d7b1744e4a68638587b12b0fa",
            "1c580bcacf3a4eff9d39a74a8996dbec",
            "42c0870ab71748cd8bcd5a273dcb9726",
            "65fb23cf538343f999895ae585c2806c",
            "05f19c2c526e498a991487b802865e94",
            "d52cd47d23714cee934e32aed1a553fb",
            "bb34adfadd054972bd25e5bff0bd515e",
            "dc3c0f141a5545a4ad9127c632151e86",
            "7a78407e28cf49babe052c5f2cd3a709",
            "519617dd351b4b1eabfa972d494a85dc",
            "327a32167f5b4201bd8d3ce4b078730c",
            "1c6bb8879ad241a29bf481643fdc9188",
            "a9005671b4b843f1b65a6e343a16a53a",
            "6d586a826a054ab684ac792bdd6498d2",
            "741f8ef10a554ad69e1548d99e4ca329",
            "662eed1a3e294c849dfea6f0311f3390",
            "19f86857196e4179977f4625cf597d75",
            "3d23a770c06140b2ba61dc8ce456e826"
          ]
        },
        "id": "gVDk6dar-WaW",
        "outputId": "3ef5dda5-62b3-47e1-a307-655d7a846460"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fafbb2e78a5f4d3d9bef625709775cec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfd4026a5b83496e92778c12e58e45a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d61c88ecddf44edc9dcf667c251a51ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f70acbfa79d42dab9dc5363d0959f7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d24d6214f0942078184e365d45e1f80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da926cfe684a4d51b5696403d85e684b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc3c0f141a5545a4ad9127c632151e86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/nirusanan/qwen2_7b_ultra_chat/commit/12cc4d869e32f5aae334d1a963559a57a9ddb8a7', commit_message='Upload tokenizer', commit_description='', oid='12cc4d869e32f5aae334d1a963559a57a9ddb8a7', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y8SrTos3-Wdn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
