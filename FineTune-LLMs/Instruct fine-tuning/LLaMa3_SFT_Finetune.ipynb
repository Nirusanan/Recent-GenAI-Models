{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofbd3c3PtZKt",
        "outputId": "e68525cf-3bca-488c-f89e-359745903652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.1.0+cu121 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.0+cu121 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.1.0+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q torch==2.1.0 --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"transformers==4.34.0\" \"datasets==2.13.0\" \"peft==0.6.2\" \"accelerate==0.21.0\" \"bitsandbytes==0.41.2.post2\" \"trl==0.4.7\" \"safetensors>=0.3.1\" \"gdown==4.6\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhRfIUPGtk-W",
        "outputId": "02a9f2a4-caeb-427a-f801-910f5a70e061"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "dJ4tExfjztrX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=userdata.get('hf_read_chelvan'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR-UQzm3gBGG",
        "outputId": "754c3b80-90b2-4a96-a9b9-6fec33a9ed0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model = \"meta-llama/Meta-Llama-3-8B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"cuda:0\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438,
          "referenced_widgets": [
            "8b561c45646748b6aca0fe9965da9918",
            "79f3986079524c22ae6edffc4e05f138",
            "67e78bf5436243bcb88f61c40bb85af9",
            "0a441cab62c14cadaa495752b3b756d4",
            "c6398a78e2824d139600a874abe1de5c",
            "d25cfa532b89453488d18c9b02ecb6dc",
            "6c4bc3b5b7c44f19b92edbe1c94ef668",
            "f6fd47351c0c435ca030b3d152ef0f01",
            "7b5e9505c401421880265e5ff0f5b88b",
            "75e567a518d34feba94a1046863c7476",
            "b0890bc871254e20bab4704e5b8f1341",
            "999e3014c3a442e789d15f71dc854de0",
            "3ace684743f94ecb99b7e23b31024cf0",
            "14a5994b3bbe490fab6e34f265793425",
            "d7370bd5ca2b490ebddc1306e941669b",
            "663f2539e9e94a469d72b2749f4daa69",
            "aab34c1393094685b46d11934ea2b740",
            "a095fc41827d49debbb91c59d488d31d",
            "23b573cb55bf4121960e6743de7ff0df",
            "7eb72dbfb8c24df5976458abc8b84e51",
            "6264e0d87d3f419b88eae4e2891666b7",
            "aafe5eff62a8451db4d641dc8a5331a8",
            "d0dc16c7d2134d66a46043c05e0bf8ce",
            "28194d6308394dee8b89c2e7bb71b7a5",
            "4e0cf97f9aec44d08a85c6b3bd8d4faf",
            "d917d961528142aab7e09b80ae5db7e2",
            "e75f13c9f8dd4827a688b3570debe6c5",
            "d68929ce4b854b63b1500c290e54a88d",
            "8714837943834e70afb14cfe6252c4dc",
            "b67baaa868e74f309ce47888fe3c79db",
            "2cf25bffea8d4163aa813961ed707fbb",
            "4ae031dbb7d14f1c91d32ba9499df1bc",
            "3d86316d56dc4abea04c31b3321e03be",
            "d72693e3e15544a886572b49fb671a3d",
            "3ee46f32fe8f4a729758ff0e726b19e3",
            "44be080fd5a34e1884fbba02110da3e7",
            "1daa3eed25754a02874e2e55ed1692b2",
            "7b3530fb389c465ba6333fbb6f658836",
            "e360769cfbe34b17846b4c7ccea9042a",
            "66c1238ce77d4a0fa72154fb77ebeb91",
            "e4f0fd1b0a544500ae862f289739a840",
            "a8cc9227262942ec9929b7245618081d",
            "213db4e92c36440c9fb1697d8427cf09",
            "75d1f3ee665947de9b6b29eb4cb7782c",
            "5d50de2bab2f4ebb9506f4ca69dcd65d",
            "a1653fee78994d4588c2c8b7908ac83d",
            "3bdfcc3b0b7a4dc3b0c4acae5792bed9",
            "9cc4f12c58054e5c8575ccaab420f595",
            "ab26118eb1654b099a070be13745e489",
            "dcd6611561154347a3f242214cf3aeb9",
            "85d72b76bb444c6988c0365a213fb6f6",
            "c0cfbe74a03e4079bf1ed339c9fce8fa",
            "e4ee8f3410624cadb759144022ff3588",
            "10a0735a2b44411c90aafeb0eddfc17b",
            "814e24f0e64241b48cf974edc7d60f3f",
            "807a262c344944efac9f71caf5106c03",
            "3ce0801a4fed4ffbaee483b8b9cce67e",
            "6d8814b4e415492b81036da1e9468c5a",
            "7b708333801541b3b2844f3705b6c4a3",
            "a61474ffb5774c919608bf233baef418",
            "b42b608b96e541cf8cfe20381d4323de",
            "66a991e4131a46c8ab9ee0aa84dc6e3b",
            "28b497de332e42eaa3e4487b3b528883",
            "30fec7d9ebad49209756195bad12e07e",
            "38f2a8126412421caf8be132144b77c1",
            "66824e56d8214ac4871fa8e0f9bd2e67",
            "07dd472ee2554b19a22139fae9c74f47",
            "97f40a197162421192b57a99c3a4f2b7",
            "b601559a440a4107998cc18457fc4aaf",
            "6733b52abd9b4b1083c590d3b11a979f",
            "b0770b1240694bc290753dbfb4e97c58",
            "d9a67f417c2040e4850e2263b5055a66",
            "44d9fd85f30d488a86926e328df706fa",
            "1ded17c593e14bf282cbc331ac79d1eb",
            "6bec0e8f7c094c858a4c11c09e52b110",
            "7a1d70a543bc4e7d9a8051030068f17d",
            "863d43cacafe4edfa190844bd295e12a",
            "e045299d8b054cb6845f0c08696a8a3d",
            "f18a8e5016e24f5d92482116cc162332",
            "03312fe6705e45da9dee9095eecfc0fc",
            "f7ea7e5267244b7ebcba89c5a11cc48b",
            "fe6948e0520649cdabe8590a035e341d",
            "96fc3f7fb5394f378a9ffa75a3ef9d3e",
            "865f314337fc40ec82d715649b5525dd",
            "6c69161ebac14425b3d65d920ecf7794",
            "6a8f60a7efca413bac45d140c8c0f610",
            "5527df40b3b14e29ac5a065e7490a8ad",
            "57dd98772d294898b071f913bef0670c",
            "4a2e8591dff3454192159f3be7f2df09",
            "35716878e3a542d3b9ad38a9407f6e75",
            "20f0e6db860947209361e238925926a8",
            "c57b50c29ff041a8a191cb71ac4b2da3",
            "08e5a136a04a46a982f85e255cb3affb",
            "d2b436663d2740e193bab6bdf544c08c",
            "d7263583e161446f91b5d3d5a99a98c0",
            "f99738e6327c486baddc43d5b4350c44",
            "46d48fc6e99b40e88b2b4cc965d4d32a",
            "d1812486fc5343758b50ad08b2992478",
            "a65dc869457c4476b4535e997bb97936",
            "5593133bacfb41a49f80472c8c5c7a19",
            "27b5ff432eb4445c949a439eb461be16",
            "6caf3a9b301546a9a3dc84a5b19945cf",
            "0bba02df34ac497cae21ba7e7db1853d",
            "5bbd436f3f404760987f6ec45fea4072",
            "ea1f5d60679645e88d5cb53ff6ef6c52",
            "93eb8a61d0614320a17f68a7e233ec4d",
            "74670b1487af454a89672550293b3647",
            "129bef54fd3146a4bcb028507123b3fd",
            "9e72804d01224db39bdab385f8f654ba",
            "5dff6d55daa14bea86d77d5efcc0a151",
            "c7a55b63eb6c4205bfada22ee257b383",
            "64b53f6adf234584a5528f8ec314e573",
            "e71e402ef7a54c698a17f85308a4bd11",
            "ec772e61c4d743c38958a9c9901e1cd6",
            "40b55b97e72d4df880c5f996f356cff3",
            "724ef6b656fb4930a5ba116a7d3c3d3c",
            "4dbc7279435d461b804fd9705652a148",
            "0469d951eb1b41869248024cb154119d",
            "f4041e3379024d0c843d796a9388d993",
            "8ef4bf1f151e47e3b3c859e6ffb406ea",
            "d11e51c9e1a648b09c4f65c8dc9ed764",
            "45d8d838e9844897a15ea548463bcad9",
            "ec117c268b6d4770935a161698224960",
            "6de5bfafb529409c8198d192be29caa0",
            "0588ee2969ff4df5b5484a9c6e6b8cad",
            "3670148c99c34a04bf71ac13b5985d59",
            "130fde61047b46e5bce2364dea9d876f",
            "1d4c059dcd5a4762998dc7140c88afa5",
            "bad2171cdb1248d98a05dff2dcdc1706",
            "b3a0a881eb834138b8c212918f7452ed",
            "c0a81df2fdcd44f480b33631e85047e1",
            "4417582bb643466f95634cdb65c7163e"
          ]
        },
        "id": "l4CN1PWKts-3",
        "outputId": "b1cc1a75-b0a8-468c-dfeb-363bb8365a5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b561c45646748b6aca0fe9965da9918"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "999e3014c3a442e789d15f71dc854de0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0dc16c7d2134d66a46043c05e0bf8ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d72693e3e15544a886572b49fb671a3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)fetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d50de2bab2f4ebb9506f4ca69dcd65d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "807a262c344944efac9f71caf5106c03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07dd472ee2554b19a22139fae9c74f47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e045299d8b054cb6845f0c08696a8a3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a2e8591dff3454192159f3be7f2df09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5593133bacfb41a49f80472c8c5c7a19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7a55b63eb6c4205bfada22ee257b383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45d8d838e9844897a15ea548463bcad9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Dataset"
      ],
      "metadata": {
        "id": "ofOEImc9xlu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1zfjg_3viiQ1IOR4AbsKiT4QCY1I1qWg8"
      ],
      "metadata": {
        "id": "0U_tOibHts6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1e00a9-df5f-4c14-f7e2-613f71c2bde2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zfjg_3viiQ1IOR4AbsKiT4QCY1I1qWg8\n",
            "To: /content/Pandas_Code_SFT_Dataset.csv\n",
            "100% 77.8k/77.8k [00:00<00:00, 3.24MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "dataset_df = pd.read_csv('Pandas_Code_SFT_Dataset.csv')\n",
        "df = dataset_df.sample(frac=1).reset_index(drop=True)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "HDRXQGhKts4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a260a429-050e-46f6-b59c-1e9d0d7f2ad9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Dataset Name', 'Columns with Sample Data', 'Question',\n",
            "       'Expected Code'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "E-n_teGLts2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "223bcb2b-2357-4bed-b38f-486533785c46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Dataset Name                           Columns with Sample Data  \\\n",
              "0        books  data = {\\n    \"book_id\": [301, 302, 303, 304, ...   \n",
              "1        sales  data = {\\n    \"invoice_date\": [\"2023-09-01\", \"...   \n",
              "2      patient  data = {\\n    \"patient_id\": [1001, 1002, 1003,...   \n",
              "3      patient  data = {\\n    \"patient_id\": [1001, 1002, 1003,...   \n",
              "4   department  data = {\\n    \"employee_id\": [101, 102, 103, 1...   \n",
              "\n",
              "                                            Question  \\\n",
              "0  Find the top 3 oldest books in terms of public...   \n",
              "1  How many invoices were generated in the last q...   \n",
              "2  Identify the male patients with Heart Disease ...   \n",
              "3  Which patients are prescribed a dosage higher ...   \n",
              "4  Identify the employee with the highest salary ...   \n",
              "\n",
              "                                       Expected Code  \n",
              "0  ```\\ndef process(df):\\n    # Sort the DataFram...  \n",
              "1  ```\\ndef process(df):\\n    # Convert the 'invo...  \n",
              "2  ```\\ndef process(df):\\n    from datetime impor...  \n",
              "3  ```\\ndef process(df):\\n    # Function to conve...  \n",
              "4  ```\\ndef process(df):\\n    # Filter for employ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c57c026a-300d-441e-b90b-9f4f66c630d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset Name</th>\n",
              "      <th>Columns with Sample Data</th>\n",
              "      <th>Question</th>\n",
              "      <th>Expected Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>books</td>\n",
              "      <td>data = {\\n    \"book_id\": [301, 302, 303, 304, ...</td>\n",
              "      <td>Find the top 3 oldest books in terms of public...</td>\n",
              "      <td>```\\ndef process(df):\\n    # Sort the DataFram...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sales</td>\n",
              "      <td>data = {\\n    \"invoice_date\": [\"2023-09-01\", \"...</td>\n",
              "      <td>How many invoices were generated in the last q...</td>\n",
              "      <td>```\\ndef process(df):\\n    # Convert the 'invo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>patient</td>\n",
              "      <td>data = {\\n    \"patient_id\": [1001, 1002, 1003,...</td>\n",
              "      <td>Identify the male patients with Heart Disease ...</td>\n",
              "      <td>```\\ndef process(df):\\n    from datetime impor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>patient</td>\n",
              "      <td>data = {\\n    \"patient_id\": [1001, 1002, 1003,...</td>\n",
              "      <td>Which patients are prescribed a dosage higher ...</td>\n",
              "      <td>```\\ndef process(df):\\n    # Function to conve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>department</td>\n",
              "      <td>data = {\\n    \"employee_id\": [101, 102, 103, 1...</td>\n",
              "      <td>Identify the employee with the highest salary ...</td>\n",
              "      <td>```\\ndef process(df):\\n    # Filter for employ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c57c026a-300d-441e-b90b-9f4f66c630d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c57c026a-300d-441e-b90b-9f4f66c630d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c57c026a-300d-441e-b90b-9f4f66c630d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6e1d1f02-daff-4a4a-961a-e2e8a2cabfa9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e1d1f02-daff-4a4a-961a-e2e8a2cabfa9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6e1d1f02-daff-4a4a-961a-e2e8a2cabfa9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 52,\n  \"fields\": [\n    {\n      \"column\": \"Dataset Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"employee\",\n          \"sales\",\n          \"transaction\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Columns with Sample Data\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"data = {\\n    \\\"employee_id\\\": [101, 102, 103, 104, 105],\\n    \\\"first_name\\\": [\\\"John\\\", \\\"Jane\\\", \\\"Robert\\\", \\\"Elena\\\", \\\"Bruce\\\"],\\n    \\\"last_name\\\": [\\\"Doe\\\", \\\"Smith\\\", \\\"Brown\\\", \\\"Taylor\\\", \\\"Lee\\\"],\\n    \\\"gender\\\": [\\\"M\\\", \\\"F\\\", \\\"M\\\", \\\"F\\\", \\\"M\\\"],\\n    \\\"department\\\": [\\\"Finance\\\", \\\"IT\\\", \\\"Sales\\\", \\\"Finance\\\", \\\"HR\\\"],\\n    \\\"salary\\\": [\\\"$60,000\\\", \\\"$65,000\\\", \\\"$55,000\\\", \\\"$63,000\\\", \\\"$58,000\\\"],\\n    \\\"nationality\\\": [\\\"USA\\\", \\\"Canada\\\", \\\"USA\\\", \\\"Mexico\\\", \\\"USA\\\"],\\n    \\\"joining_date\\\": [\\\"jan/15/2022\\\", \\\"nov/22/2021\\\", \\\"aug/09/2020\\\", \\\"feb/28/2023\\\", \\\"jun/06/2019\\\"],\\n    \\\"manager_id\\\": [105, 105, 102, 105, None]\\n}\",\n          \"data = {\\n    \\\"invoice_date\\\": [\\\"2023-09-01\\\", \\\"2023-09-02\\\", \\\"2023-09-03\\\", \\\"2023-09-04\\\", \\\"2023-09-05\\\"],\\n    \\\"customer_code\\\": [\\\"C001\\\", \\\"C005\\\", \\\"C001\\\", \\\"C003\\\", \\\"C004\\\"],\\n    \\\"customer_name\\\": [\\\"Alice\\\", \\\"Bob\\\", \\\"Alice\\\", \\\"Charlie\\\", \\\"David\\\"],\\n    \\\"gender\\\": [\\\"Male\\\", \\\"Female\\\", \\\"Male\\\", \\\"Female\\\", \\\"Male\\\"],\\n    \\\"item_code\\\": [\\\"I001\\\", \\\"I002\\\", \\\"I003\\\", \\\"I004\\\", \\\"I005\\\"],\\n    \\\"item_name\\\": [\\\"Widget A\\\", \\\"Widget B\\\", \\\"Widget C\\\", \\\"Widget D\\\", \\\"Widget E\\\"],\\n    \\\"unit_price\\\": [10, 20, 30, 40, 50],\\n    \\\"quantity\\\": [1, 2, 3, 1, 5],\\n    \\\"total_amount\\\": [10, 40, 90, 40, 250],\\n    \\\"tax\\\": [1, 4, 9, 4, 25],\\n    \\\"currency\\\": [\\\"USD\\\", \\\"USD\\\", \\\"USD\\\", \\\"USD\\\", \\\"USD\\\"],\\n    \\\"discount\\\": [0, 0, 0.05, 0, 0.1],\\n    \\\"total_discount_after\\\": [10, 40, 85.5, 40, 225]\\n}\",\n          \"data = {\\n    \\\"TransactionDate\\\": [\\\"2023-01-15\\\", \\\"2023-02-20\\\", \\\"2023-03-05\\\", \\\"2023-04-22\\\", \\\"2023-05-11\\\"],\\n    \\\"OrderID\\\": [\\\"O123\\\", \\\"O124\\\", \\\"O125\\\", \\\"O126\\\", \\\"O127\\\"],\\n    \\\"BuyerName\\\": [\\\"Emily\\\", \\\"Fiona\\\", \\\"George\\\", \\\"Henry\\\", \\\"Isla\\\"],\\n    \\\"ProductSKU\\\": [\\\"SK101\\\", \\\"SK102\\\", \\\"SK103\\\", \\\"SK104\\\", \\\"SK105\\\"],\\n    \\\"ProductName\\\": [\\\"Laptop\\\", \\\"Smartphone\\\", \\\"Smartwatch\\\", \\\"Tablet\\\", \\\"Camera\\\"],\\n    \\\"ListPrice\\\": [1000, 800, 200, 300, 500],\\n    \\\"UnitsSold\\\": [1, 2, 1, 3, 1],\\n    \\\"GrossRevenue\\\": [1000, 1600, 200, 900, 500],\\n    \\\"SalesTax\\\": [100, 160, 20, 90, 50],\\n    \\\"PaymentMode\\\": [\\\"Credit Card\\\", \\\"Debit Card\\\", \\\"Cash\\\", \\\"Bank Transfer\\\", \\\"PayPal\\\"],\\n    \\\"ShippingDate\\\": [\\\"2023-01-17\\\", \\\"2023-02-22\\\", \\\"2023-03-07\\\", \\\"2023-04-24\\\", \\\"2023-05-13\\\"],\\n    \\\"DeliveryStatus\\\": [\\\"Delivered\\\", \\\"Pending\\\", \\\"Delivered\\\", \\\"Cancelled\\\", \\\"Delivered\\\"],\\n    \\\"NetRevenueAfterTax\\\": [900, 1440, 180, 810, 450]\\n}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 52,\n        \"samples\": [\n          \"how many employees joined between 2021-01-01 to 2021-12-31?\",\n          \"How many items are categorized as low fat?\",\n          \"What is the average price of widget A sold in the last year?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Expected Code\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 52,\n        \"samples\": [\n          \"```\\ndef process(df):\\n    # Convert the 'joining_date' column to a datetime format\\n    df['joining_date'] = pd.to_datetime(df['joining_date'], format='%b/%d/%Y')\\n\\n    # Filter the dataframe for rows where the joining date falls within the given range\\n    employees_2021 = df[(df['joining_date'] >= '2021-01-01') & (df['joining_date'] <= '2021-12-31')].shape[0]\\n\\n    return f\\\"{employees_2021} employees joined between January 1, 2021, and December 31, 2021.\\\"\\n```\",\n          \"```\\ndef process(df):\\n    # Set the preferred fat content as a variable\\n    preferred_fat_content = 'Low Fat'\\n    \\n    # Filtering the DataFrame for rows based on the preferred fat content and then using 'shape' to get the count\\n    count = df[df['Item_Fat_Content'] == preferred_fat_content].shape[0]\\n\\n    # Check if the count is zero\\n    if count == 0:\\n        return f\\\"The term '{preferred_fat_content}' was not found in the records.\\\"\\n    else:\\n        return f\\\"There are {count} items that contain '{preferred_fat_content}'.\\\"\\n```\",\n          \"```\\ndef process(df):\\n    # Convert the 'invoice_date' column to datetime format\\n    df['invoice_date'] = pd.to_datetime(df['invoice_date'])\\n\\n    # Determine the start of the last year\\n    last_year_start = pd.Timestamp.now().normalize().replace(year=pd.Timestamp.now().year - 1, month=1, day=1)\\n\\n    # Filter the DataFrame for \\\"Widget A\\\" sold in the last year\\n    widget_a_sales = df[(df['item_name'] == \\\"Widget A\\\") & (df['invoice_date'] >= last_year_start)]\\n\\n    # Check if there are any sales of \\\"Widget A\\\" in the last year\\n    if widget_a_sales.empty:\\n        return \\\"No sales of Widget A in the last year.\\\"\\n\\n    # Calculate the average price\\n    average_price = widget_a_sales['unit_price'].mean()\\n\\n    return f\\\"The average price of Widget A sold in the last year is ${average_price:.2f}.\\\"\\n```\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(df)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMf34S-vhUDT",
        "outputId": "6b8d11c2-8ebc-4e81-ecfa-63241848a173"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Dataset Name', 'Columns with Sample Data', 'Question', 'Expected Code'],\n",
              "    num_rows: 52\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_prompt_template(examples):\n",
        "  instruction = examples['Question']\n",
        "  context = examples[\"Columns with Sample Data\"]\n",
        "  response = examples['Expected Code']\n",
        "\n",
        "  full_prompt = f\"\"\"Below is an instruction that describes a task. Write a Python function using Pandas to accomplish the task described below.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "header columns with sample data:\n",
        "{context}\n",
        "\n",
        "### Response:\n",
        "{response}\n",
        "\n",
        "### End\n",
        "\"\"\"\n",
        "  return { \"text\": full_prompt }\n",
        "\n",
        "dataset = dataset.map(apply_prompt_template)\n",
        "print(dataset[\"text\"][0])"
      ],
      "metadata": {
        "id": "FFczl85TuKXm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523,
          "referenced_widgets": [
            "f7aedfb1c5c24849a4b3ed9bf9ce95b4",
            "82e149bbc3e04ae3b44dd672ee76380a",
            "2782da05a152488d89c3db6d6662604f",
            "8f6b1fa68c004bccb7e51324b5ad6de5",
            "1faf0288031f470aba90e6756e6d2c3b",
            "4d921a9c05894c7c857bc9c4e513cc16",
            "94b6779844b040698c3395a496eb4977",
            "37b284a6c1a44b6b9c9ce08d60414908",
            "8c22e48541004ed39c498a672dd5f512",
            "72ff486df298424ea76718f5c71c0874",
            "ec19108377154a1e9e97e42b25b4257c"
          ]
        },
        "outputId": "1243f969-e43e-4fa7-ddbd-8c11387c7661"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7aedfb1c5c24849a4b3ed9bf9ce95b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a Python function using Pandas to accomplish the task described below.\n",
            "\n",
            "### Instruction:\n",
            "Find the top 3 oldest books in terms of publication year and list their titles, authors, and genres?\n",
            "\n",
            "header columns with sample data:\n",
            "data = {\n",
            "    \"book_id\": [301, 302, 303, 304, 305],\n",
            "    \"title\": [\"The Mystery of Time\", \"Journey Through Stars\", \"Secrets of the Ocean\", \"The Lost Civilization\", \"Worlds Beyond\"],\n",
            "    \"author\": [\"Alice Johnson\", \"John Smith\", \"Emily White\", \"David Brown\", \"Sarah Green\"],\n",
            "    \"genre\": [\"Mystery\", \"Science Fiction\", \"Adventure\", \"Historical\", \"Fantasy\"],\n",
            "    \"publication_year\": [2018, 2020, 2019, 2017, 2021],\n",
            "    \"pages\": [320, 250, 400, 500, 300],\n",
            "    \"borrowed_times\": [25, 15, 35, 20, 10],\n",
            "    \"available_copies\": [2, 3, 1, 4, 5]\n",
            "}\n",
            "\n",
            "### Response:\n",
            "```\n",
            "def process(df):\n",
            "    # Sort the DataFrame by publication year in ascending order to find the oldest books\n",
            "    oldest_books = df.sort_values(by='publication_year').head(3)\n",
            "\n",
            "    return oldest_books[['title', 'author', 'genre', 'publication_year']]\n",
            "```\n",
            "\n",
            "### End\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=['q_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'k_proj', 'v_proj'] # Choose all linear layers from the model\n",
        ")"
      ],
      "metadata": {
        "id": "gywjJzNguNYa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "\n",
        "training_params = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=4,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=50,\n",
        "    logging_steps=1,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=50,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    report_to=\"tensorboard\"\n",
        ")"
      ],
      "metadata": {
        "id": "tuJ2Q0L0uRUe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "3kFrxEY4xXpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=1024,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_params,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "oregCe-tuWq2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "59144bfdf8634022a427b9b36d0d5481",
            "8aa3c112f74646ae9fbc71e25027208b",
            "d03c3c73c3364db3b53ea93df5321a90",
            "8cb610c81f294bd5b6f23c0a7369f5bd",
            "2d8c0db96dc942f7ac0e6b1ff78e32dd",
            "483f3ea6b1834687a388b90391a14080",
            "69d8add4dcdb4ccc924028fd87858e00",
            "d0fbda320db641e7922f198e1ec8618f",
            "1cddb2cc88c447798067e191f1fa90bf",
            "900815622b404f888e65c0c01f9f6c2e",
            "489e8849c5b043c3846f462353ef5c6d"
          ]
        },
        "outputId": "42a05aad-b184-4b57-e768-e190180c6dac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:136: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59144bfdf8634022a427b9b36d0d5481"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 11:33, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.902700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.992800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.201300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.667000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.887100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.570300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.851600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.419500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.384400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.410900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.352400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.532300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.379500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.292500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.252700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.436600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.339200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.572500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.167100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.343100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.384000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.308700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.192100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.333500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.189800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.175500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.198800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.151200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.166800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.130000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.147800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.112100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.324700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.387600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.112500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.142500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.102300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.244900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.070400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.072700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.075900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.079000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.110500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.057900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=0.321178385540843, metrics={'train_runtime': 711.9554, 'train_samples_per_second': 0.281, 'train_steps_per_second': 0.07, 'total_flos': 4982587941126144.0, 'train_loss': 0.321178385540843, 'epoch': 3.85})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "UecKo0lkuZPN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "C7aXPMcmxcN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Below is an instruction that describes a task. Write a Python function using Pandas to accomplish the task described below.\n",
        "\n",
        "### Instruction:\n",
        "how many unique items are there\n",
        "\n",
        "header columns with sample data:\n",
        "data = {\n",
        "    \"invoice_date\": [\"2023-09-11\", \"2023-09-12\", \"2023-09-13\", \"2023-09-14\", \"2023-09-15\"],\n",
        "    \"customer_code\": [\"C006\", \"C007\", \"C006\", \"C008\", \"C009\"],\n",
        "    \"customer_name\": [\"Frank\", \"Grace\", \"Frank\", \"Hannah\", \"Ian\"],\n",
        "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
        "    \"item_code\": [\"I005\", \"I004\", \"I003\", \"I002\", \"I001\"],\n",
        "    \"item_name\": [\"Widget E\", \"Widget D\", \"Widget C\", \"Widget B\", \"Widget A\"],\n",
        "    \"unit_price\": [\"$50\", \"$40\", \"$30\", \"$20\", \"$10\"],\n",
        "    \"quantity\": [2, 3, 1, 4, 5],\n",
        "    \"total_amount\": [100, 120, 30, 80, 50],\n",
        "    \"tax\": [10, 12, 3, 8, 5],\n",
        "    \"currency\": [\"USD\", \"USD\", \"USD\", \"EUR\", \"EUR\"],\n",
        "    \"discount\": [0.05, 0, 0, 0.1, 0.05],\n",
        "    \"total_discount_after\": [95, 120, 30, 72, 47.5]\n",
        "}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "result = pipe(prompt, max_length=550)\n",
        "generated_text = result[0]['generated_text']\n",
        "print(generated_text.split(\"### End\")[0])"
      ],
      "metadata": {
        "id": "6XqIBmmtudW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f553cac9-e141-45ed-9c6d-75a49a8e2c99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Below is an instruction that describes a task. Write a Python function using Pandas to accomplish the task described below.\n",
            "\n",
            "### Instruction:\n",
            "how many unique items are there\n",
            "\n",
            "header columns with sample data:\n",
            "data = {\n",
            "    \"invoice_date\": [\"2023-09-11\", \"2023-09-12\", \"2023-09-13\", \"2023-09-14\", \"2023-09-15\"],\n",
            "    \"customer_code\": [\"C006\", \"C007\", \"C006\", \"C008\", \"C009\"],\n",
            "    \"customer_name\": [\"Frank\", \"Grace\", \"Frank\", \"Hannah\", \"Ian\"],\n",
            "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
            "    \"item_code\": [\"I005\", \"I004\", \"I003\", \"I002\", \"I001\"],\n",
            "    \"item_name\": [\"Widget E\", \"Widget D\", \"Widget C\", \"Widget B\", \"Widget A\"],\n",
            "    \"unit_price\": [\"$50\", \"$40\", \"$30\", \"$20\", \"$10\"],\n",
            "    \"quantity\": [2, 3, 1, 4, 5],\n",
            "    \"total_amount\": [100, 120, 30, 80, 50],\n",
            "    \"tax\": [10, 12, 3, 8, 5],\n",
            "    \"currency\": [\"USD\", \"USD\", \"USD\", \"EUR\", \"EUR\"],\n",
            "    \"discount\": [0.05, 0, 0, 0.1, 0.05],\n",
            "    \"total_discount_after\": [95, 120, 30, 72, 47.5]\n",
            "}\n",
            "\n",
            "### Response:\n",
            "```\n",
            "def process(df):\n",
            "    # Count the unique items\n",
            "    unique_items = df['item_name'].nunique()\n",
            "    \n",
            "    return f\"Number of unique items: {unique_items}\"\n",
            "```\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Below is an instruction that describes a task. Write a Python function using Pandas to accomplish the task described below.\n",
        "\n",
        "### Instruction:\n",
        "top 3 products has higest discounts\n",
        "\n",
        "header columns with sample data:\n",
        "data = {\n",
        "    \"invoice_date\": [\"2023-09-11\", \"2023-09-12\", \"2023-09-13\", \"2023-09-14\", \"2023-09-15\"],\n",
        "    \"customer_code\": [\"C006\", \"C007\", \"C006\", \"C008\", \"C009\"],\n",
        "    \"customer_name\": [\"Frank\", \"Grace\", \"Frank\", \"Hannah\", \"Ian\"],\n",
        "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
        "    \"item_code\": [\"I005\", \"I004\", \"I003\", \"I002\", \"I001\"],\n",
        "    \"item_name\": [\"Widget E\", \"Widget D\", \"Widget C\", \"Widget B\", \"Widget A\"],\n",
        "    \"unit_price\": [\"$50\", \"$40\", \"$30\", \"$20\", \"$10\"],\n",
        "    \"quantity\": [2, 3, 1, 4, 5],\n",
        "    \"total_amount\": [100, 120, 30, 80, 50],\n",
        "    \"tax\": [10, 12, 3, 8, 5],\n",
        "    \"currency\": [\"USD\", \"USD\", \"USD\", \"EUR\", \"EUR\"],\n",
        "    \"discount\": [0.05, 0, 0, 0.1, 0.05],\n",
        "    \"total_discount_after\": [95, 120, 30, 72, 47.5]\n",
        "}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "result = pipe(prompt, max_length=550)\n",
        "generated_text = result[0]['generated_text']\n",
        "print(generated_text.split(\"### End\")[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITaKuqA1mZd1",
        "outputId": "333bf29a-4482-4f57-e832-7239379ee6bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Below is an instruction that describes a task. Write a Python function using Pandas to accomplish the task described below.\n",
            "\n",
            "### Instruction:\n",
            "top 3 products has higest discounts\n",
            "\n",
            "header columns with sample data:\n",
            "data = {\n",
            "    \"invoice_date\": [\"2023-09-11\", \"2023-09-12\", \"2023-09-13\", \"2023-09-14\", \"2023-09-15\"],\n",
            "    \"customer_code\": [\"C006\", \"C007\", \"C006\", \"C008\", \"C009\"],\n",
            "    \"customer_name\": [\"Frank\", \"Grace\", \"Frank\", \"Hannah\", \"Ian\"],\n",
            "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
            "    \"item_code\": [\"I005\", \"I004\", \"I003\", \"I002\", \"I001\"],\n",
            "    \"item_name\": [\"Widget E\", \"Widget D\", \"Widget C\", \"Widget B\", \"Widget A\"],\n",
            "    \"unit_price\": [\"$50\", \"$40\", \"$30\", \"$20\", \"$10\"],\n",
            "    \"quantity\": [2, 3, 1, 4, 5],\n",
            "    \"total_amount\": [100, 120, 30, 80, 50],\n",
            "    \"tax\": [10, 12, 3, 8, 5],\n",
            "    \"currency\": [\"USD\", \"USD\", \"USD\", \"EUR\", \"EUR\"],\n",
            "    \"discount\": [0.05, 0, 0, 0.1, 0.05],\n",
            "    \"total_discount_after\": [95, 120, 30, 72, 47.5]\n",
            "}\n",
            "\n",
            "### Response:\n",
            "```\n",
            "def process(df):\n",
            "    # Calculate the total discount for each product\n",
            "    df['total_discount'] = df['total_amount'] * df['discount']\n",
            "\n",
            "    # Group by product and sum the total discount\n",
            "    product_discounts = df.groupby('item_name')['total_discount'].sum()\n",
            "\n",
            "    # Sort the discounts in descending order and take the top 3\n",
            "    top_3_products = product_discounts.sort_values(ascending=False).head(3)\n",
            "\n",
            "    return top_3_products\n",
            "```\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Below is an instruction that describes a task. Write a Python function using Pandas to accomplish the task described below.\n",
        "\n",
        "### Instruction:\n",
        "Which item has customer C006 spent the most money on\n",
        "\n",
        "header columns with sample data:\n",
        "data = {\n",
        "    \"invoice_date\": [\"2023-09-11\", \"2023-09-12\", \"2023-09-13\", \"2023-09-14\", \"2023-09-15\"],\n",
        "    \"customer_code\": [\"C006\", \"C007\", \"C006\", \"C008\", \"C009\"],\n",
        "    \"customer_name\": [\"Frank\", \"Grace\", \"Frank\", \"Hannah\", \"Ian\"],\n",
        "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
        "    \"item_code\": [\"I005\", \"I004\", \"I003\", \"I002\", \"I001\"],\n",
        "    \"item_name\": [\"Widget E\", \"Widget D\", \"Widget C\", \"Widget B\", \"Widget A\"],\n",
        "    \"unit_price\": [\"$50\", \"$40\", \"$30\", \"$20\", \"$10\"],\n",
        "    \"quantity\": [2, 3, 1, 4, 5],\n",
        "    \"total_amount\": [100, 120, 30, 80, 50],\n",
        "    \"tax\": [10, 12, 3, 8, 5],\n",
        "    \"currency\": [\"USD\", \"USD\", \"USD\", \"EUR\", \"EUR\"],\n",
        "    \"discount\": [0.05, 0, 0, 0.1, 0.05],\n",
        "    \"total_discount_after\": [95, 120, 30, 72, 47.5]\n",
        "}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "result = pipe(prompt, max_length=550)\n",
        "generated_text = result[0]['generated_text']\n",
        "print(generated_text.split(\"### End\")[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOcq2q8ood9L",
        "outputId": "db7cbd40-6012-40c7-fa2e-597980e864c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Below is an instruction that describes a task. Write a Python function using Pandas to accomplish the task described below.\n",
            "\n",
            "### Instruction:\n",
            "Which item has customer C006 spent the most money on\n",
            "\n",
            "header columns with sample data:\n",
            "data = {\n",
            "    \"invoice_date\": [\"2023-09-11\", \"2023-09-12\", \"2023-09-13\", \"2023-09-14\", \"2023-09-15\"],\n",
            "    \"customer_code\": [\"C006\", \"C007\", \"C006\", \"C008\", \"C009\"],\n",
            "    \"customer_name\": [\"Frank\", \"Grace\", \"Frank\", \"Hannah\", \"Ian\"],\n",
            "    \"gender\": [\"Male\", \"Female\", \"Male\", \"Female\", \"Male\"],\n",
            "    \"item_code\": [\"I005\", \"I004\", \"I003\", \"I002\", \"I001\"],\n",
            "    \"item_name\": [\"Widget E\", \"Widget D\", \"Widget C\", \"Widget B\", \"Widget A\"],\n",
            "    \"unit_price\": [\"$50\", \"$40\", \"$30\", \"$20\", \"$10\"],\n",
            "    \"quantity\": [2, 3, 1, 4, 5],\n",
            "    \"total_amount\": [100, 120, 30, 80, 50],\n",
            "    \"tax\": [10, 12, 3, 8, 5],\n",
            "    \"currency\": [\"USD\", \"USD\", \"USD\", \"EUR\", \"EUR\"],\n",
            "    \"discount\": [0.05, 0, 0, 0.1, 0.05],\n",
            "    \"total_discount_after\": [95, 120, 30, 72, 47.5]\n",
            "}\n",
            "\n",
            "### Response:\n",
            "```\n",
            "def process(df):\n",
            "    # Check if customer C006 exists in the DataFrame\n",
            "    if 'C006' not in df['customer_code'].values:\n",
            "        return \"Customer C006 does not exist.\"\n",
            "\n",
            "    # Filter the DataFrame for entries where customer_code is 'C006'\n",
            "    customer_sales = df[df['customer_code'] == 'C006']['total_amount'].sum()\n",
            "\n",
            "    # Identify the item with the highest total sales amount for customer C006\n",
            "    max_sales_item = df[(df['customer_code'] == 'C006') & (df['total_amount'] == customer_sales)]['item_name'].values[0]\n",
            "\n",
            "    return f\"The item with the highest total sales amount for customer C006 is {max_sales_item}.\"\n",
            "```\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push fine-tuned model to hub"
      ],
      "metadata": {
        "id": "Anm7EJYcvBre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=userdata.get('niru_hf_write'))"
      ],
      "metadata": {
        "id": "h7Jp_nUAu_KD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fdc6d00-3a05-4a1e-8540-ffa1058678d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"Llama-3-8B_SFT_Finetune_Pandas_Code\")"
      ],
      "metadata": {
        "id": "chc8OZruvrxK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    \"/content/Llama-3-8B_SFT_Finetune_Pandas_Code\",\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "\n",
        "# Merge LoRA and base model\n",
        "merged_model = model.merge_and_unload()"
      ],
      "metadata": {
        "id": "FhHhK2UhvsPR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "276309e9795b47ecbc47b990229c244e",
            "9732c061ca6a43efa373d3630a3979c5",
            "64f7571a87bf4780a3cebc2a985843ce",
            "162a0670f73a419fa38ac9dcc87d6231",
            "82deb6bb4bb3446ca28b4693937e5591",
            "5e9ac9246fcb4eb7b81ca8594c52a701",
            "0176286a70f44aa19d2d6db40f29e2fb",
            "7bfe575f50314654a2d62bc39f52eb48",
            "d088e765f1a1499d9e65c273a2f5c4bd",
            "820e3817a4554823b797ecae9c1fe67e",
            "236f9ed136354ccd99277cbd950adc66"
          ]
        },
        "outputId": "10f482f2-9786-4e2f-dc52-f59e9cbce2cc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "276309e9795b47ecbc47b990229c244e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# push merged model to the hub\n",
        "merged_model.push_to_hub(\"Llama-3-8B_SFT_Finetune_Pandas_Code\",private=True,safe_serialization=True)\n",
        "tokenizer.push_to_hub(\"Llama-3-8B_SFT_Finetune_Pandas_Code\",private=True)"
      ],
      "metadata": {
        "id": "dRJL6YK-v0jY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "9027e6ab1d614569a29a8c58e776e45a",
            "3d3a4d5c10e540349c883cac1f49c2f5",
            "59eb55b11c2d404784e8b4d2ba608acc",
            "915ee5f176664e0cb86a9afcd714e061",
            "956cbe1de9d34fdaa9d120d780dd6f33",
            "f0a32deffee341529a25190982d556c8",
            "616d0d79b6fa460eb2ab490cc0129c49",
            "84e4794ec68e407b97789381fa6b7f99",
            "0653bb3113764a6daa684d8691248c77",
            "a4fe78e57b424778a085663baeef284f",
            "48ebd0493f134cfc8f3b6acce2ee126c",
            "1c3ee39416af4eff8d8a25307b6f4103",
            "b327473d11e74fe4b251024a1bd7d06a",
            "4e175a7154054a0595ea98ccee6ae126",
            "855e33847e894fe1922f8844ba19882a",
            "48cbc44e60254915af3ca517623f6844",
            "9afffef263ff490abb5b1ebe97fb105a",
            "456fceb5982441038fbd5045307de64a",
            "7182794729a0429bb77a4103afb33ece",
            "83ca868bfd6a4366a09d3fddf4577413",
            "d229276cfec143ad8ea62e4a9c5daf1a",
            "c4b4a99191d24b6b868ffbbe8aa96a50",
            "0d39f1bcf79e473481adf43577c9afce",
            "714c0d17e8774110b9f21c311adc0367",
            "ec255a74a42b4d329c9ccb05f03a5dee",
            "1a38ea8268344616a8297bd9aed42866",
            "3fc82422c5294997953afe41c4269e81",
            "cc8ef5b7a80f44c4957fc7fda41a49ee",
            "b63805d8511e488b9526d1d9e35eee0a",
            "01237469f9c04f059d453e93f31e25b2",
            "851a7867eea34632a43c2513c8fac900",
            "6f549d4c84a641e698584626aed20d6f",
            "b2c7e60dbb094145883115444046eec4",
            "f55385215bc94b3fabe08b69cce326d7",
            "6406190f7aa84e5f8345fb9b7b33e76a",
            "3f9cbadb7a854a39a69a56c25937747e",
            "4fe54874be17416e8103cb865b72b21b",
            "e2aaabfbd3134052951f600c1ece784f",
            "031ee23e709e43799dedecc9ce3a6f07",
            "c501a9d09d304fa4976b8c7df64d8e49",
            "c6e9fb264861405496590fad9ee31caf",
            "c6e37485523d451d9b8348b6a94b1183",
            "80f80ffbbb4d4c4d90e56f3cd3aee89e",
            "70a43512910d4d1b9927bbe6d6ae504a",
            "7dc326447bda42ea9016582384aeea98",
            "d218415a12614588b1cc9334835fe309",
            "070e0e5ce2d94f51bbd7b9691f82223c",
            "e406a6efdb3d46a0a6e6f3612b6ccfc6",
            "de095fefb6864c669f4a49b0147254a6",
            "65eb6190ca834ea99a63cff086456401",
            "2936a4bd73a246eab7cf3f9e33e2f862",
            "398380fe101c4614ad3c07744af608b8",
            "3f8fdea5c8a94089b99aad6cbd65d1d5",
            "1f41b21245934f5b95095efa5c3998b4",
            "3d34d96fd0144f94ae0de229a79f1db6"
          ]
        },
        "outputId": "1655ee5e-8ca3-4b7c-cf25-746fd4b5dec4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/2.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9027e6ab1d614569a29a8c58e776e45a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/9.83G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c3ee39416af4eff8d8a25307b6f4103"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d39f1bcf79e473481adf43577c9afce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f55385215bc94b3fabe08b69cce326d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dc326447bda42ea9016582384aeea98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/nirusanan/Llama-3-8B_SFT_Finetune_Pandas_Code/commit/de8529a5f2f3073c02605b00d38838c4089047cc', commit_message='Upload tokenizer', commit_description='', oid='de8529a5f2f3073c02605b00d38838c4089047cc', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}
